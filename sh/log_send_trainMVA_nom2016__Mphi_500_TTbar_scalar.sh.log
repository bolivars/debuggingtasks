~/CMSSW_10_4_0/src ~/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork/sh
~/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork/sh ~/CMSSW_10_4_0/src
DataSetInfo              : [dataset] : Added class "Signal"
DataSetInfo              : [dataset] : Added class "Background"
[93m
 --> I found 1 signal and 1 background processes.
Please check if these numbers seem to be correct! 
[0m
                         : Add Tree Events of type Signal with 110159 events
                         : Add Tree Events of type Background with 12130744 events
                         : Dataset[dataset] : Class index : 0  name : Signal
                         : Dataset[dataset] : Class index : 1  name : Background
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 20)                300       
_________________________________________________________________
dense_2 (Dense)              (None, 15)                315       
_________________________________________________________________
dense_3 (Dense)              (None, 15)                240       
_________________________________________________________________
dense_4 (Dense)              (None, 10)                160       
_________________________________________________________________
dense_5 (Dense)              (None, 2)                 22        
=================================================================
Total params: 1,037
Trainable params: 1,037
Non-trainable params: 0
_________________________________________________________________
Factory                  : Booking method: [1mBDT[0m
                         : 
DataSetFactory           : [dataset] : Number of events in input trees
                         : Dataset[dataset] :     Signal     requirement: "mt2ll > 80. && nbJet >= 1 && (( nJetMine > 2) || ( nJetMine == 2 && nbJet > 1))"
                         : Dataset[dataset] :     Signal          -- number of events passed: 16754  / sum of weights: 130.849
                         : Dataset[dataset] :     Signal          -- efficiency             : 0.061247
                         : Dataset[dataset] :     Background requirement: "mt2ll > 80. && nbJet >= 1 && (( nJetMine > 2) || ( nJetMine == 2 && nbJet > 1))"
                         : Dataset[dataset] :     Background      -- number of events passed: 230456  / sum of weights: 260.88
                         : Dataset[dataset] :     Background      -- efficiency             : 0.019535
                         : Dataset[dataset] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Dataset[dataset] :  you have opted for interpreting the requested number of training/testing events
                         :  to be the number of events AFTER your preselection cuts
                         : 
                         : Number of training and testing events
                         : ---------------------------------------------------------------------------
                         : Signal     -- training events            : 11727
                         : Signal     -- testing events             : 5026
                         : Signal     -- training and testing events: 16753
                         : Dataset[dataset] : Signal     -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.152089
                         : Background -- training events            : 161319
                         : Background -- testing events             : 69136
                         : Background -- training and testing events: 230455
                         : Dataset[dataset] : Background -- due to the preselection a scaling factor has been applied to the numbers of requested events: 0.0189977
                         : 
DataSetInfo              : Correlation matrix (Signal):
                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------
                         :                       nbJet    mblt METcorrected_pt   mt2ll dphillmet   mt2bl   massT cosphill costhetall     r2l   r2l4j reco_weight dark_pt overlapping_factor
                         :              nbJet:  +1.000  -0.119          -0.010  -0.013    -0.024  -0.002  +0.005   -0.116     -0.116  -0.002  +0.084      -0.115  -0.074             -0.116
                         :               mblt:  -0.119  +1.000          +0.218  +0.227    -0.003  +0.425  +0.410   +0.145     +0.145  -0.332  -0.173      +0.145  +0.096             +0.145
                         :    METcorrected_pt:  -0.010  +0.218          +1.000  +0.733    -0.001  +0.570  +0.884   -0.184     -0.184  +0.298  +0.622      -0.185  -0.119             -0.185
                         :              mt2ll:  -0.013  +0.227          +0.733  +1.000    +0.011  +0.516  +0.670   -0.235     -0.235  +0.015  +0.435      -0.236  -0.152             -0.236
                         :          dphillmet:  -0.024  -0.003          -0.001  +0.011    +1.000  +0.017  +0.003   +0.024     +0.024  -0.002  -0.009      +0.024  +0.025             +0.024
                         :              mt2bl:  -0.002  +0.425          +0.570  +0.516    +0.017  +1.000  +0.708   +0.093     +0.092  -0.066  +0.091      +0.093  +0.042             +0.093
                         :              massT:  +0.005  +0.410          +0.884  +0.670    +0.003  +0.708  +1.000   -0.099     -0.100  -0.013  +0.265      -0.100  -0.057             -0.100
                         :           cosphill:  -0.116  +0.145          -0.184  -0.235    +0.024  +0.093  -0.099   +1.000     +1.000  -0.100  -0.251      +1.000  +0.640             +1.000
                         :         costhetall:  -0.116  +0.145          -0.184  -0.235    +0.024  +0.092  -0.100   +1.000     +1.000  -0.101  -0.251      +1.000  +0.642             +1.000
                         :                r2l:  -0.002  -0.332          +0.298  +0.015    -0.002  -0.066  -0.013   -0.100     -0.101  +1.000  +0.605      -0.101  -0.079             -0.101
                         :              r2l4j:  +0.084  -0.173          +0.622  +0.435    -0.009  +0.091  +0.265   -0.251     -0.251  +0.605  +1.000      -0.252  -0.172             -0.252
                         :        reco_weight:  -0.115  +0.145          -0.185  -0.236    +0.024  +0.093  -0.100   +1.000     +1.000  -0.101  -0.252      +1.000  +0.640             +1.000
                         :            dark_pt:  -0.074  +0.096          -0.119  -0.152    +0.025  +0.042  -0.057   +0.640     +0.642  -0.079  -0.172      +0.640  +1.000             +0.642
                         : overlapping_factor:  -0.116  +0.145          -0.185  -0.236    +0.024  +0.093  -0.100   +1.000     +1.000  -0.101  -0.252      +1.000  +0.642             +1.000
                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------
DataSetInfo              : Correlation matrix (Background):
                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------
                         :                       nbJet    mblt METcorrected_pt   mt2ll dphillmet   mt2bl   massT cosphill costhetall     r2l   r2l4j reco_weight dark_pt overlapping_factor
                         :              nbJet:  +1.000  -0.189          -0.027  -0.023    +0.000  -0.185  -0.080   -0.260     -0.260  +0.008  +0.135      -0.260  -0.164             -0.260
                         :               mblt:  -0.189  +1.000          -0.130  +0.135    +0.005  +0.388  +0.343   +0.186     +0.187  -0.349  -0.331      +0.187  +0.130             +0.188
                         :    METcorrected_pt:  -0.027  -0.130          +1.000  +0.122    +0.004  +0.062  +0.374   +0.015     +0.016  +0.708  +0.593      +0.015  +0.012             +0.015
                         :              mt2ll:  -0.023  +0.135          +0.122  +1.000    -0.002  +0.152  +0.204   -0.025     -0.025  -0.071  -0.027      -0.026  -0.006             -0.025
                         :          dphillmet:  +0.000  +0.005          +0.004  -0.002    +1.000  +0.002  +0.004   -0.001     -0.001  +0.002  -0.000      -0.001  -0.004             -0.001
                         :              mt2bl:  -0.185  +0.388          +0.062  +0.152    +0.002  +1.000  +0.622   +0.275     +0.276  -0.206  -0.304      +0.276  +0.202             +0.278
                         :              massT:  -0.080  +0.343          +0.374  +0.204    +0.004  +0.622  +1.000   +0.162     +0.162  -0.071  -0.245      +0.162  +0.126             +0.163
                         :           cosphill:  -0.260  +0.186          +0.015  -0.025    -0.001  +0.275  +0.162   +1.000     +1.000  -0.054  -0.142      +1.000  +0.660             +1.000
                         :         costhetall:  -0.260  +0.187          +0.016  -0.025    -0.001  +0.276  +0.162   +1.000     +1.000  -0.055  -0.143      +1.000  +0.662             +1.000
                         :                r2l:  +0.008  -0.349          +0.708  -0.071    +0.002  -0.206  -0.071   -0.054     -0.055  +1.000  +0.715      -0.054  -0.044             -0.055
                         :              r2l4j:  +0.135  -0.331          +0.593  -0.027    -0.000  -0.304  -0.245   -0.142     -0.143  +0.715  +1.000      -0.143  -0.100             -0.143
                         :        reco_weight:  -0.260  +0.187          +0.015  -0.026    -0.001  +0.276  +0.162   +1.000     +1.000  -0.054  -0.143      +1.000  +0.658             +1.000
                         :            dark_pt:  -0.164  +0.130          +0.012  -0.006    -0.004  +0.202  +0.126   +0.660     +0.662  -0.044  -0.100      +0.658  +1.000             +0.663
                         : overlapping_factor:  -0.260  +0.188          +0.015  -0.025    -0.001  +0.278  +0.163   +1.000     +1.000  -0.055  -0.143      +1.000  +0.663             +1.000
                         : ----------------------------------------------------------------------------------------------------------------------------------------------------------------
DataSetFactory           : [dataset] :  
                         : 
Factory                  : Booking method: [1mPyKeras[0m
                         : 
PyKeras                  : [dataset] : Create Transformation "N" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'nbJet' <---> Output : variable 'nbJet'
                         : Input : variable 'mblt' <---> Output : variable 'mblt'
                         : Input : variable 'METcorrected_pt' <---> Output : variable 'METcorrected_pt'
                         : Input : variable 'mt2ll' <---> Output : variable 'mt2ll'
                         : Input : variable 'dphillmet' <---> Output : variable 'dphillmet'
                         : Input : variable 'mt2bl' <---> Output : variable 'mt2bl'
                         : Input : variable 'massT' <---> Output : variable 'massT'
                         : Input : variable 'cosphill' <---> Output : variable 'cosphill'
                         : Input : variable 'costhetall' <---> Output : variable 'costhetall'
                         : Input : variable 'r2l' <---> Output : variable 'r2l'
                         : Input : variable 'r2l4j' <---> Output : variable 'r2l4j'
                         : Input : variable 'reco_weight' <---> Output : variable 'reco_weight'
                         : Input : variable 'dark_pt' <---> Output : variable 'dark_pt'
                         : Input : variable 'overlapping_factor' <---> Output : variable 'overlapping_factor'
                         : Load model from file: /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKeras1.h5
Factory                  : [1mTrain all methods[0m
Factory                  : [dataset] : Create Transformation "I" with events from all classes.
                         : 
                         : Transformation, Variable selection : 
                         : Input : variable 'nbJet' <---> Output : variable 'nbJet'
                         : Input : variable 'mblt' <---> Output : variable 'mblt'
                         : Input : variable 'METcorrected_pt' <---> Output : variable 'METcorrected_pt'
                         : Input : variable 'mt2ll' <---> Output : variable 'mt2ll'
                         : Input : variable 'dphillmet' <---> Output : variable 'dphillmet'
                         : Input : variable 'mt2bl' <---> Output : variable 'mt2bl'
                         : Input : variable 'massT' <---> Output : variable 'massT'
                         : Input : variable 'cosphill' <---> Output : variable 'cosphill'
                         : Input : variable 'costhetall' <---> Output : variable 'costhetall'
                         : Input : variable 'r2l' <---> Output : variable 'r2l'
                         : Input : variable 'r2l4j' <---> Output : variable 'r2l4j'
                         : Input : variable 'reco_weight' <---> Output : variable 'reco_weight'
                         : Input : variable 'dark_pt' <---> Output : variable 'dark_pt'
                         : Input : variable 'overlapping_factor' <---> Output : variable 'overlapping_factor'
TFHandler_Factory        :           Variable                  Mean                  RMS          [        Min                  Max ]
                         : -------------------------------------------------------------------------------------------------------------
                         :              nbJet:              1.6965             0.51732   [              1.0000              5.0000 ]
                         :               mblt:              114.05              45.410   [              13.959              1075.0 ]
                         :    METcorrected_pt:              122.84              63.598   [              2.3742              2966.7 ]
                         :              mt2ll:              94.281              29.452   [              80.000              732.17 ]
                         :          dphillmet:           0.0081357              2.1245   [             -3.1416              3.1416 ]
                         :              mt2bl:              224.02              115.37   [              77.199              2916.5 ]
                         :              massT:              411.20              144.88   [              137.44              2482.7 ]
                         :           cosphill:             -47.414              49.213   [             -99.000             0.99998 ]
                         :         costhetall:             -47.171              49.444   [             -99.000             0.96380 ]
                         :                r2l:              1.0387             0.59807   [            0.010137              14.697 ]
                         :              r2l4j:             0.34864             0.16792   [           0.0038577              7.9306 ]
                         :        reco_weight:             -46.395              50.193   [             -99.000              6.2835 ]
                         :            dark_pt:              126.23              325.43   [             -99.000              9077.3 ]
                         : overlapping_factor:             -46.539              50.050   [             -99.000              85.542 ]
                         : -------------------------------------------------------------------------------------------------------------
                         : Ranking input variables (method unspecific)...
IdTransformation         : Ranking result (top variable is best ranked)
                         : -------------------------------------------
                         : Rank : Variable           : Separation
                         : -------------------------------------------
                         :    1 : mt2ll              : 6.165e-01
                         :    2 : METcorrected_pt    : 5.646e-01
                         :    3 : massT              : 4.455e-01
                         :    4 : r2l4j              : 3.496e-01
                         :    5 : mt2bl              : 3.361e-01
                         :    6 : mblt               : 1.506e-01
                         :    7 : r2l                : 3.599e-02
                         :    8 : nbJet              : 1.095e-02
                         :    9 : dphillmet          : 1.002e-02
                         :   10 : reco_weight        : 8.414e-03
                         :   11 : dark_pt            : 8.130e-03
                         :   12 : overlapping_factor : 1.770e-03
                         :   13 : costhetall         : 4.095e-04
                         :   14 : cosphill           : 2.850e-04
                         : -------------------------------------------
Factory                  : Train method: BDT for Classification
                         : 
BDT                      : #events: (reweighted) sig: 86523 bkg: 86523
                         : #events: (unweighted) sig: 11727 bkg: 161319
                         : Training 250 Decision Trees ... patience please
                         : Elapsed time for training with 173046 events: 66.7 sec         
BDT                      : [dataset] : Evaluation of BDT on training sample (173046 events)
                         : Elapsed time for evaluation of 173046 events: 6.07 sec       
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_BDT.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_BDT.class.C[0m
                         : /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/TMVA.root:/dataset/Method_BDT/BDT
Factory                  : Training finished
                         : 
Factory                  : Train method: PyKeras for Classification
                         : 
                         : 
                         : [1m================================================================[0m
                         : [1mH e l p   f o r   M V A   m e t h o d   [ PyKeras ] :[0m
                         : 
                         : Keras is a high-level API for the Theano and Tensorflow packages.
                         : This method wraps the training and predictions steps of the Keras
                         : Python package for TMVA, so that dataloading, preprocessing and
                         : evaluation can be done within the TMVA system. To use this Keras
                         : interface, you have to generate a model with Keras first. Then,
                         : this model can be loaded and trained in TMVA.
                         : 
                         : 
                         : <Suppress this message by specifying "!H" in the booking option>
                         : [1m================================================================[0m
                         : 
TFHandler_PyKeras        :           Variable                  Mean                  RMS          [        Min                  Max ]
                         : -------------------------------------------------------------------------------------------------------------
                         :              nbJet:            -0.65175             0.25866   [             -1.0000              1.0000 ]
                         :               mblt:            -0.81133            0.085596   [             -1.0000              1.0000 ]
                         :    METcorrected_pt:            -0.91872            0.042908   [             -1.0000              1.0000 ]
                         :              mt2ll:            -0.95620            0.090319   [             -1.0000              1.0000 ]
                         :          dphillmet:           0.0025897             0.67624   [             -1.0000              1.0000 ]
                         :              mt2bl:            -0.89658            0.081264   [             -1.0000              1.0000 ]
                         :              massT:            -0.76654             0.12355   [             -1.0000              1.0000 ]
                         :           cosphill:            0.031728             0.98426   [             -1.0000              1.0000 ]
                         :         costhetall:            0.036962             0.98925   [             -1.0000              1.0000 ]
                         :                r2l:            -0.85993            0.081445   [             -1.0000              1.0000 ]
                         :              r2l4j:            -0.91301            0.042369   [             -1.0000              1.0000 ]
                         :        reco_weight:         -0.00070468             0.95348   [             -1.0000              1.0000 ]
                         :            dark_pt:            -0.95091            0.070928   [             -1.0000              1.0000 ]
                         : overlapping_factor:            -0.43145             0.54243   [             -1.0000              1.0000 ]
                         : -------------------------------------------------------------------------------------------------------------
                         : Option SaveBestOnly: Only model weights with smallest validation loss will be stored
Train on 173046 samples, validate on 74162 samples
Epoch 1/50

   250/173046 [..............................] - ETA: 8:23 - loss: 0.7433 - acc: 0.0560 - mean_squared_error: 0.2704
  5500/173046 [..............................] - ETA: 23s - loss: 0.4348 - acc: 0.8847 - mean_squared_error: 0.1356 
 11250/173046 [>.............................] - ETA: 11s - loss: 0.3316 - acc: 0.9097 - mean_squared_error: 0.0983
 17000/173046 [=>............................] - ETA: 8s - loss: 0.3026 - acc: 0.9171 - mean_squared_error: 0.0862 
 22750/173046 [==>...........................] - ETA: 6s - loss: 0.2796 - acc: 0.9204 - mean_squared_error: 0.0805
 28500/173046 [===>..........................] - ETA: 5s - loss: 0.2704 - acc: 0.9230 - mean_squared_error: 0.0764
 34250/173046 [====>.........................] - ETA: 4s - loss: 0.2648 - acc: 0.9247 - mean_squared_error: 0.0737
 40000/173046 [=====>........................] - ETA: 3s - loss: 0.2572 - acc: 0.9267 - mean_squared_error: 0.0710
 45750/173046 [======>.......................] - ETA: 3s - loss: 0.2543 - acc: 0.9267 - mean_squared_error: 0.0699
 51500/173046 [=======>......................] - ETA: 2s - loss: 0.2468 - acc: 0.9274 - mean_squared_error: 0.0682
 57250/173046 [========>.....................] - ETA: 2s - loss: 0.2436 - acc: 0.9279 - mean_squared_error: 0.0670
 63000/173046 [=========>....................] - ETA: 2s - loss: 0.2357 - acc: 0.9291 - mean_squared_error: 0.0654
 68750/173046 [==========>...................] - ETA: 2s - loss: 0.2289 - acc: 0.9304 - mean_squared_error: 0.0638
 74500/173046 [===========>..................] - ETA: 1s - loss: 0.2247 - acc: 0.9316 - mean_squared_error: 0.0624
 80250/173046 [============>.................] - ETA: 1s - loss: 0.2216 - acc: 0.9327 - mean_squared_error: 0.0610
 86000/173046 [=============>................] - ETA: 1s - loss: 0.2177 - acc: 0.9338 - mean_squared_error: 0.0597
 91750/173046 [==============>...............] - ETA: 1s - loss: 0.2131 - acc: 0.9351 - mean_squared_error: 0.0584
 97500/173046 [===============>..............] - ETA: 1s - loss: 0.2094 - acc: 0.9362 - mean_squared_error: 0.0573
103250/173046 [================>.............] - ETA: 1s - loss: 0.2046 - acc: 0.9374 - mean_squared_error: 0.0560
109000/173046 [=================>............] - ETA: 1s - loss: 0.2010 - acc: 0.9386 - mean_squared_error: 0.0548
114750/173046 [==================>...........] - ETA: 0s - loss: 0.1976 - acc: 0.9396 - mean_squared_error: 0.0538
120500/173046 [===================>..........] - ETA: 0s - loss: 0.1942 - acc: 0.9404 - mean_squared_error: 0.0529
126250/173046 [====================>.........] - ETA: 0s - loss: 0.1926 - acc: 0.9411 - mean_squared_error: 0.0522
132000/173046 [=====================>........] - ETA: 0s - loss: 0.1901 - acc: 0.9420 - mean_squared_error: 0.0513
137750/173046 [======================>.......] - ETA: 0s - loss: 0.1876 - acc: 0.9426 - mean_squared_error: 0.0507
143500/173046 [=======================>......] - ETA: 0s - loss: 0.1847 - acc: 0.9431 - mean_squared_error: 0.0502
149250/173046 [========================>.....] - ETA: 0s - loss: 0.1816 - acc: 0.9437 - mean_squared_error: 0.0495
155000/173046 [=========================>....] - ETA: 0s - loss: 0.1804 - acc: 0.9442 - mean_squared_error: 0.0490
160750/173046 [==========================>...] - ETA: 0s - loss: 0.1774 - acc: 0.9446 - mean_squared_error: 0.0487
166500/173046 [===========================>..] - ETA: 0s - loss: 0.1749 - acc: 0.9452 - mean_squared_error: 0.0481
172250/173046 [============================>.] - ETA: 0s - loss: 0.1722 - acc: 0.9458 - mean_squared_error: 0.0475
173046/173046 [==============================] - 3s 15us/step - loss: 0.1716 - acc: 0.9459 - mean_squared_error: 0.0474 - val_loss: 7.4405e-04 - val_acc: 0.9609 - val_mean_squared_error: 0.0329

Epoch 00001: val_loss improved from inf to 0.00074, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 2/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0290 - acc: 0.9680 - mean_squared_error: 0.0252
  5750/173046 [..............................] - ETA: 1s - loss: 0.0914 - acc: 0.9630 - mean_squared_error: 0.0313
 11500/173046 [>.............................] - ETA: 1s - loss: 0.1062 - acc: 0.9620 - mean_squared_error: 0.0318
 17250/173046 [=>............................] - ETA: 1s - loss: 0.1042 - acc: 0.9627 - mean_squared_error: 0.0310
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.1016 - acc: 0.9633 - mean_squared_error: 0.0306
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.1083 - acc: 0.9623 - mean_squared_error: 0.0320
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.1160 - acc: 0.9602 - mean_squared_error: 0.0338
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.1191 - acc: 0.9600 - mean_squared_error: 0.0341
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.1194 - acc: 0.9606 - mean_squared_error: 0.0337
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.1211 - acc: 0.9609 - mean_squared_error: 0.0334
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.1194 - acc: 0.9614 - mean_squared_error: 0.0329
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.1188 - acc: 0.9614 - mean_squared_error: 0.0329
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.1175 - acc: 0.9616 - mean_squared_error: 0.0328
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.1163 - acc: 0.9616 - mean_squared_error: 0.0327
 80500/173046 [============>.................] - ETA: 0s - loss: 0.1149 - acc: 0.9622 - mean_squared_error: 0.0322
 86250/173046 [=============>................] - ETA: 0s - loss: 0.1142 - acc: 0.9624 - mean_squared_error: 0.0320
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.1134 - acc: 0.9626 - mean_squared_error: 0.0319
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.1135 - acc: 0.9626 - mean_squared_error: 0.0319
103500/173046 [================>.............] - ETA: 0s - loss: 0.1134 - acc: 0.9627 - mean_squared_error: 0.0318
109250/173046 [=================>............] - ETA: 0s - loss: 0.1127 - acc: 0.9628 - mean_squared_error: 0.0316
115000/173046 [==================>...........] - ETA: 0s - loss: 0.1111 - acc: 0.9631 - mean_squared_error: 0.0315
120750/173046 [===================>..........] - ETA: 0s - loss: 0.1104 - acc: 0.9632 - mean_squared_error: 0.0314
126500/173046 [====================>.........] - ETA: 0s - loss: 0.1099 - acc: 0.9633 - mean_squared_error: 0.0313
132250/173046 [=====================>........] - ETA: 0s - loss: 0.1094 - acc: 0.9634 - mean_squared_error: 0.0312
138000/173046 [======================>.......] - ETA: 0s - loss: 0.1088 - acc: 0.9636 - mean_squared_error: 0.0310
143750/173046 [=======================>......] - ETA: 0s - loss: 0.1093 - acc: 0.9637 - mean_squared_error: 0.0309
149500/173046 [========================>.....] - ETA: 0s - loss: 0.1097 - acc: 0.9638 - mean_squared_error: 0.0308
155250/173046 [=========================>....] - ETA: 0s - loss: 0.1101 - acc: 0.9638 - mean_squared_error: 0.0308
161000/173046 [==========================>...] - ETA: 0s - loss: 0.1094 - acc: 0.9640 - mean_squared_error: 0.0307
166750/173046 [===========================>..] - ETA: 0s - loss: 0.1093 - acc: 0.9639 - mean_squared_error: 0.0307
172500/173046 [============================>.] - ETA: 0s - loss: 0.1086 - acc: 0.9640 - mean_squared_error: 0.0306
173046/173046 [==============================] - 2s 11us/step - loss: 0.1085 - acc: 0.9640 - mean_squared_error: 0.0306 - val_loss: 7.1919e-04 - val_acc: 0.9650 - val_mean_squared_error: 0.0302

Epoch 00002: val_loss improved from 0.00074 to 0.00072, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 3/50

   250/173046 [..............................] - ETA: 5s - loss: 0.1990 - acc: 0.9720 - mean_squared_error: 0.0241
  5750/173046 [..............................] - ETA: 1s - loss: 0.1485 - acc: 0.9612 - mean_squared_error: 0.0351
 11500/173046 [>.............................] - ETA: 1s - loss: 0.1311 - acc: 0.9634 - mean_squared_error: 0.0320
 17250/173046 [=>............................] - ETA: 1s - loss: 0.1203 - acc: 0.9650 - mean_squared_error: 0.0304
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.1149 - acc: 0.9663 - mean_squared_error: 0.0294
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.1096 - acc: 0.9665 - mean_squared_error: 0.0289
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.1031 - acc: 0.9667 - mean_squared_error: 0.0286
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.1010 - acc: 0.9667 - mean_squared_error: 0.0285
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.1008 - acc: 0.9667 - mean_squared_error: 0.0285
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.1006 - acc: 0.9667 - mean_squared_error: 0.0286
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0988 - acc: 0.9669 - mean_squared_error: 0.0285
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0981 - acc: 0.9669 - mean_squared_error: 0.0284
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0982 - acc: 0.9670 - mean_squared_error: 0.0284
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0970 - acc: 0.9669 - mean_squared_error: 0.0284
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0975 - acc: 0.9667 - mean_squared_error: 0.0286
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0965 - acc: 0.9672 - mean_squared_error: 0.0281
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0980 - acc: 0.9671 - mean_squared_error: 0.0282
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0985 - acc: 0.9670 - mean_squared_error: 0.0282
103500/173046 [================>.............] - ETA: 0s - loss: 0.0984 - acc: 0.9671 - mean_squared_error: 0.0281
109250/173046 [=================>............] - ETA: 0s - loss: 0.0990 - acc: 0.9673 - mean_squared_error: 0.0280
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0999 - acc: 0.9670 - mean_squared_error: 0.0282
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0995 - acc: 0.9668 - mean_squared_error: 0.0284
126500/173046 [====================>.........] - ETA: 0s - loss: 0.1000 - acc: 0.9668 - mean_squared_error: 0.0284
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0991 - acc: 0.9671 - mean_squared_error: 0.0282
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0989 - acc: 0.9673 - mean_squared_error: 0.0281
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0988 - acc: 0.9673 - mean_squared_error: 0.0282
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0987 - acc: 0.9674 - mean_squared_error: 0.0281
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0980 - acc: 0.9674 - mean_squared_error: 0.0281
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0991 - acc: 0.9672 - mean_squared_error: 0.0282
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0988 - acc: 0.9672 - mean_squared_error: 0.0283
172500/173046 [============================>.] - ETA: 0s - loss: 0.0985 - acc: 0.9673 - mean_squared_error: 0.0282
173046/173046 [==============================] - 2s 11us/step - loss: 0.0985 - acc: 0.9673 - mean_squared_error: 0.0282 - val_loss: 4.7510e-04 - val_acc: 0.9680 - val_mean_squared_error: 0.0272

Epoch 00003: val_loss improved from 0.00072 to 0.00048, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 4/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0595 - acc: 0.9800 - mean_squared_error: 0.0210
  5750/173046 [..............................] - ETA: 1s - loss: 0.0966 - acc: 0.9673 - mean_squared_error: 0.0280
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0991 - acc: 0.9685 - mean_squared_error: 0.0269
 17250/173046 [=>............................] - ETA: 1s - loss: 0.1029 - acc: 0.9671 - mean_squared_error: 0.0281
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.0997 - acc: 0.9667 - mean_squared_error: 0.0284
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.0963 - acc: 0.9675 - mean_squared_error: 0.0279
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.0947 - acc: 0.9672 - mean_squared_error: 0.0281
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.0933 - acc: 0.9675 - mean_squared_error: 0.0279
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0934 - acc: 0.9680 - mean_squared_error: 0.0275
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0918 - acc: 0.9682 - mean_squared_error: 0.0272
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0894 - acc: 0.9684 - mean_squared_error: 0.0269
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0911 - acc: 0.9683 - mean_squared_error: 0.0269
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0909 - acc: 0.9686 - mean_squared_error: 0.0267
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0915 - acc: 0.9685 - mean_squared_error: 0.0268
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0901 - acc: 0.9687 - mean_squared_error: 0.0267
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0895 - acc: 0.9689 - mean_squared_error: 0.0266
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0911 - acc: 0.9689 - mean_squared_error: 0.0266
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0921 - acc: 0.9689 - mean_squared_error: 0.0266
103500/173046 [================>.............] - ETA: 0s - loss: 0.0931 - acc: 0.9687 - mean_squared_error: 0.0268
109250/173046 [=================>............] - ETA: 0s - loss: 0.0931 - acc: 0.9690 - mean_squared_error: 0.0266
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0929 - acc: 0.9689 - mean_squared_error: 0.0266
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0921 - acc: 0.9691 - mean_squared_error: 0.0264
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0917 - acc: 0.9691 - mean_squared_error: 0.0265
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0910 - acc: 0.9688 - mean_squared_error: 0.0267
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0911 - acc: 0.9689 - mean_squared_error: 0.0266
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0913 - acc: 0.9689 - mean_squared_error: 0.0266
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0914 - acc: 0.9689 - mean_squared_error: 0.0266
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0916 - acc: 0.9688 - mean_squared_error: 0.0267
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0920 - acc: 0.9685 - mean_squared_error: 0.0270
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0924 - acc: 0.9684 - mean_squared_error: 0.0270
172500/173046 [============================>.] - ETA: 0s - loss: 0.0928 - acc: 0.9682 - mean_squared_error: 0.0272
173046/173046 [==============================] - 2s 11us/step - loss: 0.0927 - acc: 0.9682 - mean_squared_error: 0.0272 - val_loss: 4.8207e-04 - val_acc: 0.9698 - val_mean_squared_error: 0.0257

Epoch 00004: val_loss did not improve
Epoch 5/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0302 - acc: 0.9800 - mean_squared_error: 0.0201
  5750/173046 [..............................] - ETA: 1s - loss: 0.0820 - acc: 0.9692 - mean_squared_error: 0.0271
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0937 - acc: 0.9702 - mean_squared_error: 0.0258
 17500/173046 [==>...........................] - ETA: 1s - loss: 0.0997 - acc: 0.9695 - mean_squared_error: 0.0263
 23750/173046 [===>..........................] - ETA: 1s - loss: 0.1007 - acc: 0.9679 - mean_squared_error: 0.0276
 30000/173046 [====>.........................] - ETA: 1s - loss: 0.1023 - acc: 0.9672 - mean_squared_error: 0.0283
 36250/173046 [=====>........................] - ETA: 1s - loss: 0.1009 - acc: 0.9676 - mean_squared_error: 0.0279
 42500/173046 [======>.......................] - ETA: 1s - loss: 0.0991 - acc: 0.9678 - mean_squared_error: 0.0277
 48750/173046 [=======>......................] - ETA: 1s - loss: 0.0982 - acc: 0.9683 - mean_squared_error: 0.0274
 55000/173046 [========>.....................] - ETA: 1s - loss: 0.0960 - acc: 0.9683 - mean_squared_error: 0.0275
 61250/173046 [=========>....................] - ETA: 0s - loss: 0.0937 - acc: 0.9687 - mean_squared_error: 0.0271
 67500/173046 [==========>...................] - ETA: 0s - loss: 0.0924 - acc: 0.9687 - mean_squared_error: 0.0270
 73750/173046 [===========>..................] - ETA: 0s - loss: 0.0942 - acc: 0.9683 - mean_squared_error: 0.0273
 80000/173046 [============>.................] - ETA: 0s - loss: 0.0945 - acc: 0.9683 - mean_squared_error: 0.0273
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0937 - acc: 0.9682 - mean_squared_error: 0.0273
 92500/173046 [===============>..............] - ETA: 0s - loss: 0.0941 - acc: 0.9680 - mean_squared_error: 0.0275
 98750/173046 [================>.............] - ETA: 0s - loss: 0.0952 - acc: 0.9678 - mean_squared_error: 0.0276
105000/173046 [=================>............] - ETA: 0s - loss: 0.0951 - acc: 0.9680 - mean_squared_error: 0.0275
111250/173046 [==================>...........] - ETA: 0s - loss: 0.0963 - acc: 0.9678 - mean_squared_error: 0.0276
117500/173046 [===================>..........] - ETA: 0s - loss: 0.0966 - acc: 0.9677 - mean_squared_error: 0.0276
123750/173046 [====================>.........] - ETA: 0s - loss: 0.0971 - acc: 0.9676 - mean_squared_error: 0.0277
130000/173046 [=====================>........] - ETA: 0s - loss: 0.0964 - acc: 0.9679 - mean_squared_error: 0.0275
136250/173046 [======================>.......] - ETA: 0s - loss: 0.0957 - acc: 0.9679 - mean_squared_error: 0.0274
142500/173046 [=======================>......] - ETA: 0s - loss: 0.0964 - acc: 0.9680 - mean_squared_error: 0.0275
147750/173046 [========================>.....] - ETA: 0s - loss: 0.0965 - acc: 0.9680 - mean_squared_error: 0.0275
153500/173046 [=========================>....] - ETA: 0s - loss: 0.0957 - acc: 0.9679 - mean_squared_error: 0.0276
159250/173046 [==========================>...] - ETA: 0s - loss: 0.0962 - acc: 0.9678 - mean_squared_error: 0.0276
165000/173046 [===========================>..] - ETA: 0s - loss: 0.0953 - acc: 0.9678 - mean_squared_error: 0.0276
170750/173046 [============================>.] - ETA: 0s - loss: 0.0947 - acc: 0.9679 - mean_squared_error: 0.0275
173046/173046 [==============================] - 2s 10us/step - loss: 0.0944 - acc: 0.9679 - mean_squared_error: 0.0275 - val_loss: 5.7758e-04 - val_acc: 0.9681 - val_mean_squared_error: 0.0275

Epoch 00005: val_loss did not improve
Epoch 6/50

   250/173046 [..............................] - ETA: 5s - loss: 0.1289 - acc: 0.9560 - mean_squared_error: 0.0379
  6000/173046 [>.............................] - ETA: 1s - loss: 0.0807 - acc: 0.9693 - mean_squared_error: 0.0261
 11750/173046 [=>............................] - ETA: 1s - loss: 0.0891 - acc: 0.9683 - mean_squared_error: 0.0267
 17500/173046 [==>...........................] - ETA: 1s - loss: 0.0915 - acc: 0.9679 - mean_squared_error: 0.0273
 23250/173046 [===>..........................] - ETA: 1s - loss: 0.0923 - acc: 0.9668 - mean_squared_error: 0.0280
 29000/173046 [====>.........................] - ETA: 1s - loss: 0.0940 - acc: 0.9675 - mean_squared_error: 0.0274
 34750/173046 [=====>........................] - ETA: 1s - loss: 0.0924 - acc: 0.9677 - mean_squared_error: 0.0274
 40500/173046 [======>.......................] - ETA: 1s - loss: 0.0902 - acc: 0.9681 - mean_squared_error: 0.0272
 46250/173046 [=======>......................] - ETA: 1s - loss: 0.0922 - acc: 0.9669 - mean_squared_error: 0.0281
 52000/173046 [========>.....................] - ETA: 1s - loss: 0.0941 - acc: 0.9671 - mean_squared_error: 0.0280
 57750/173046 [=========>....................] - ETA: 1s - loss: 0.0940 - acc: 0.9670 - mean_squared_error: 0.0281
 63500/173046 [==========>...................] - ETA: 0s - loss: 0.0922 - acc: 0.9672 - mean_squared_error: 0.0277
 69250/173046 [===========>..................] - ETA: 0s - loss: 0.0932 - acc: 0.9674 - mean_squared_error: 0.0276
 75000/173046 [============>.................] - ETA: 0s - loss: 0.0925 - acc: 0.9677 - mean_squared_error: 0.0274
 80750/173046 [============>.................] - ETA: 0s - loss: 0.0914 - acc: 0.9682 - mean_squared_error: 0.0270
 86500/173046 [=============>................] - ETA: 0s - loss: 0.0912 - acc: 0.9683 - mean_squared_error: 0.0269
 92250/173046 [==============>...............] - ETA: 0s - loss: 0.0900 - acc: 0.9684 - mean_squared_error: 0.0268
 98000/173046 [===============>..............] - ETA: 0s - loss: 0.0911 - acc: 0.9680 - mean_squared_error: 0.0271
103750/173046 [================>.............] - ETA: 0s - loss: 0.0910 - acc: 0.9682 - mean_squared_error: 0.0271
109500/173046 [=================>............] - ETA: 0s - loss: 0.0901 - acc: 0.9684 - mean_squared_error: 0.0269
115250/173046 [==================>...........] - ETA: 0s - loss: 0.0899 - acc: 0.9685 - mean_squared_error: 0.0268
121000/173046 [===================>..........] - ETA: 0s - loss: 0.0895 - acc: 0.9686 - mean_squared_error: 0.0267
126750/173046 [====================>.........] - ETA: 0s - loss: 0.0902 - acc: 0.9686 - mean_squared_error: 0.0267
132500/173046 [=====================>........] - ETA: 0s - loss: 0.0903 - acc: 0.9687 - mean_squared_error: 0.0266
138250/173046 [======================>.......] - ETA: 0s - loss: 0.0895 - acc: 0.9687 - mean_squared_error: 0.0266
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0907 - acc: 0.9685 - mean_squared_error: 0.0268
149750/173046 [========================>.....] - ETA: 0s - loss: 0.0903 - acc: 0.9687 - mean_squared_error: 0.0267
155500/173046 [=========================>....] - ETA: 0s - loss: 0.0900 - acc: 0.9688 - mean_squared_error: 0.0267
161500/173046 [==========================>...] - ETA: 0s - loss: 0.0892 - acc: 0.9689 - mean_squared_error: 0.0266
167750/173046 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9689 - mean_squared_error: 0.0266
173046/173046 [==============================] - 2s 11us/step - loss: 0.0888 - acc: 0.9689 - mean_squared_error: 0.0266 - val_loss: 8.3864e-04 - val_acc: 0.9639 - val_mean_squared_error: 0.0322

Epoch 00006: val_loss did not improve
Epoch 7/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1733 - acc: 0.9480 - mean_squared_error: 0.0450
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0793 - acc: 0.9680 - mean_squared_error: 0.0270
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0829 - acc: 0.9675 - mean_squared_error: 0.0271
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0941 - acc: 0.9681 - mean_squared_error: 0.0270
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0925 - acc: 0.9685 - mean_squared_error: 0.0268
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0904 - acc: 0.9682 - mean_squared_error: 0.0270
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0924 - acc: 0.9681 - mean_squared_error: 0.0271
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0895 - acc: 0.9690 - mean_squared_error: 0.0263
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0883 - acc: 0.9687 - mean_squared_error: 0.0265
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0920 - acc: 0.9684 - mean_squared_error: 0.0268
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0955 - acc: 0.9676 - mean_squared_error: 0.0275
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0961 - acc: 0.9670 - mean_squared_error: 0.0280
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0970 - acc: 0.9668 - mean_squared_error: 0.0281
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0968 - acc: 0.9671 - mean_squared_error: 0.0279
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0946 - acc: 0.9671 - mean_squared_error: 0.0279
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0936 - acc: 0.9674 - mean_squared_error: 0.0276
100250/173046 [================>.............] - ETA: 0s - loss: 0.0929 - acc: 0.9674 - mean_squared_error: 0.0276
106500/173046 [=================>............] - ETA: 0s - loss: 0.0935 - acc: 0.9673 - mean_squared_error: 0.0278
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0919 - acc: 0.9674 - mean_squared_error: 0.0277
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0928 - acc: 0.9674 - mean_squared_error: 0.0277
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0932 - acc: 0.9676 - mean_squared_error: 0.0276
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0924 - acc: 0.9678 - mean_squared_error: 0.0274
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0930 - acc: 0.9680 - mean_squared_error: 0.0272
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0916 - acc: 0.9682 - mean_squared_error: 0.0271
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0917 - acc: 0.9683 - mean_squared_error: 0.0270
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0916 - acc: 0.9683 - mean_squared_error: 0.0270
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0913 - acc: 0.9683 - mean_squared_error: 0.0270
169000/173046 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9683 - mean_squared_error: 0.0270
173046/173046 [==============================] - 2s 10us/step - loss: 0.0914 - acc: 0.9683 - mean_squared_error: 0.0270 - val_loss: 7.0012e-04 - val_acc: 0.9660 - val_mean_squared_error: 0.0298

Epoch 00007: val_loss did not improve
Epoch 8/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1421 - acc: 0.9760 - mean_squared_error: 0.0226
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0945 - acc: 0.9723 - mean_squared_error: 0.0237
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0918 - acc: 0.9720 - mean_squared_error: 0.0243
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0954 - acc: 0.9704 - mean_squared_error: 0.0257
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0899 - acc: 0.9703 - mean_squared_error: 0.0255
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0888 - acc: 0.9709 - mean_squared_error: 0.0251
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0836 - acc: 0.9706 - mean_squared_error: 0.0252
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0851 - acc: 0.9700 - mean_squared_error: 0.0256
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0851 - acc: 0.9703 - mean_squared_error: 0.0253
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0871 - acc: 0.9700 - mean_squared_error: 0.0256
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0861 - acc: 0.9699 - mean_squared_error: 0.0257
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0855 - acc: 0.9699 - mean_squared_error: 0.0257
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0862 - acc: 0.9698 - mean_squared_error: 0.0258
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0854 - acc: 0.9699 - mean_squared_error: 0.0258
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0852 - acc: 0.9697 - mean_squared_error: 0.0259
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0864 - acc: 0.9698 - mean_squared_error: 0.0258
100250/173046 [================>.............] - ETA: 0s - loss: 0.0852 - acc: 0.9699 - mean_squared_error: 0.0258
106500/173046 [=================>............] - ETA: 0s - loss: 0.0860 - acc: 0.9698 - mean_squared_error: 0.0258
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0852 - acc: 0.9699 - mean_squared_error: 0.0257
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0858 - acc: 0.9698 - mean_squared_error: 0.0258
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0855 - acc: 0.9696 - mean_squared_error: 0.0259
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0851 - acc: 0.9698 - mean_squared_error: 0.0257
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0859 - acc: 0.9697 - mean_squared_error: 0.0258
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0861 - acc: 0.9697 - mean_squared_error: 0.0258
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0864 - acc: 0.9695 - mean_squared_error: 0.0260
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0881 - acc: 0.9695 - mean_squared_error: 0.0261
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0883 - acc: 0.9695 - mean_squared_error: 0.0261
169000/173046 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9695 - mean_squared_error: 0.0261
173046/173046 [==============================] - 2s 10us/step - loss: 0.0896 - acc: 0.9692 - mean_squared_error: 0.0263 - val_loss: 6.8206e-04 - val_acc: 0.9652 - val_mean_squared_error: 0.0304

Epoch 00008: val_loss did not improve
Epoch 9/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1589 - acc: 0.9600 - mean_squared_error: 0.0336
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0632 - acc: 0.9698 - mean_squared_error: 0.0256
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0903 - acc: 0.9685 - mean_squared_error: 0.0268
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0847 - acc: 0.9697 - mean_squared_error: 0.0257
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0837 - acc: 0.9697 - mean_squared_error: 0.0256
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0810 - acc: 0.9697 - mean_squared_error: 0.0257
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0873 - acc: 0.9688 - mean_squared_error: 0.0264
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0894 - acc: 0.9682 - mean_squared_error: 0.0269
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0872 - acc: 0.9685 - mean_squared_error: 0.0266
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0886 - acc: 0.9684 - mean_squared_error: 0.0266
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0873 - acc: 0.9685 - mean_squared_error: 0.0265
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0870 - acc: 0.9684 - mean_squared_error: 0.0266
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0874 - acc: 0.9685 - mean_squared_error: 0.0266
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0857 - acc: 0.9686 - mean_squared_error: 0.0266
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0865 - acc: 0.9686 - mean_squared_error: 0.0267
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0881 - acc: 0.9686 - mean_squared_error: 0.0267
100250/173046 [================>.............] - ETA: 0s - loss: 0.0885 - acc: 0.9686 - mean_squared_error: 0.0266
106500/173046 [=================>............] - ETA: 0s - loss: 0.0872 - acc: 0.9687 - mean_squared_error: 0.0266
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0872 - acc: 0.9687 - mean_squared_error: 0.0266
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0875 - acc: 0.9687 - mean_squared_error: 0.0265
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0863 - acc: 0.9689 - mean_squared_error: 0.0264
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0871 - acc: 0.9690 - mean_squared_error: 0.0263
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0873 - acc: 0.9690 - mean_squared_error: 0.0264
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0873 - acc: 0.9690 - mean_squared_error: 0.0264
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0866 - acc: 0.9692 - mean_squared_error: 0.0262
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0871 - acc: 0.9692 - mean_squared_error: 0.0262
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0876 - acc: 0.9692 - mean_squared_error: 0.0263
169000/173046 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9693 - mean_squared_error: 0.0263
173046/173046 [==============================] - 2s 10us/step - loss: 0.0880 - acc: 0.9693 - mean_squared_error: 0.0263 - val_loss: 5.7520e-04 - val_acc: 0.9685 - val_mean_squared_error: 0.0269

Epoch 00009: val_loss did not improve
Epoch 10/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1707 - acc: 0.9640 - mean_squared_error: 0.0299
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0989 - acc: 0.9675 - mean_squared_error: 0.0278
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0911 - acc: 0.9678 - mean_squared_error: 0.0281
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0957 - acc: 0.9679 - mean_squared_error: 0.0276
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0917 - acc: 0.9689 - mean_squared_error: 0.0268
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0938 - acc: 0.9683 - mean_squared_error: 0.0270
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0928 - acc: 0.9690 - mean_squared_error: 0.0265
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0919 - acc: 0.9694 - mean_squared_error: 0.0263
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0882 - acc: 0.9702 - mean_squared_error: 0.0256
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0897 - acc: 0.9696 - mean_squared_error: 0.0260
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0890 - acc: 0.9694 - mean_squared_error: 0.0262
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0876 - acc: 0.9695 - mean_squared_error: 0.0261
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0883 - acc: 0.9694 - mean_squared_error: 0.0261
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0876 - acc: 0.9695 - mean_squared_error: 0.0261
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0870 - acc: 0.9695 - mean_squared_error: 0.0261
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0866 - acc: 0.9696 - mean_squared_error: 0.0260
100250/173046 [================>.............] - ETA: 0s - loss: 0.0871 - acc: 0.9696 - mean_squared_error: 0.0260
106500/173046 [=================>............] - ETA: 0s - loss: 0.0870 - acc: 0.9694 - mean_squared_error: 0.0261
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0863 - acc: 0.9694 - mean_squared_error: 0.0261
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0862 - acc: 0.9694 - mean_squared_error: 0.0261
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0860 - acc: 0.9693 - mean_squared_error: 0.0262
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0865 - acc: 0.9692 - mean_squared_error: 0.0263
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0867 - acc: 0.9691 - mean_squared_error: 0.0263
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0860 - acc: 0.9694 - mean_squared_error: 0.0261
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0855 - acc: 0.9692 - mean_squared_error: 0.0262
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0862 - acc: 0.9692 - mean_squared_error: 0.0263
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0871 - acc: 0.9692 - mean_squared_error: 0.0263
169000/173046 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9692 - mean_squared_error: 0.0263
173046/173046 [==============================] - 2s 10us/step - loss: 0.0869 - acc: 0.9692 - mean_squared_error: 0.0262 - val_loss: 4.5711e-04 - val_acc: 0.9703 - val_mean_squared_error: 0.0252

Epoch 00010: val_loss improved from 0.00048 to 0.00046, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 11/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0351 - acc: 0.9760 - mean_squared_error: 0.0209
  5750/173046 [..............................] - ETA: 1s - loss: 0.0682 - acc: 0.9699 - mean_squared_error: 0.0251
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0726 - acc: 0.9698 - mean_squared_error: 0.0255
 17250/173046 [=>............................] - ETA: 1s - loss: 0.0768 - acc: 0.9696 - mean_squared_error: 0.0261
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.0830 - acc: 0.9697 - mean_squared_error: 0.0263
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.0891 - acc: 0.9686 - mean_squared_error: 0.0275
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.0926 - acc: 0.9683 - mean_squared_error: 0.0275
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.0942 - acc: 0.9687 - mean_squared_error: 0.0271
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0951 - acc: 0.9687 - mean_squared_error: 0.0271
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0925 - acc: 0.9691 - mean_squared_error: 0.0266
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0924 - acc: 0.9689 - mean_squared_error: 0.0268
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0909 - acc: 0.9690 - mean_squared_error: 0.0267
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0918 - acc: 0.9688 - mean_squared_error: 0.0269
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0928 - acc: 0.9689 - mean_squared_error: 0.0269
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0920 - acc: 0.9688 - mean_squared_error: 0.0269
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0912 - acc: 0.9687 - mean_squared_error: 0.0270
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0908 - acc: 0.9689 - mean_squared_error: 0.0268
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0912 - acc: 0.9686 - mean_squared_error: 0.0271
103500/173046 [================>.............] - ETA: 0s - loss: 0.0922 - acc: 0.9687 - mean_squared_error: 0.0270
109250/173046 [=================>............] - ETA: 0s - loss: 0.0906 - acc: 0.9688 - mean_squared_error: 0.0268
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0905 - acc: 0.9687 - mean_squared_error: 0.0270
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0911 - acc: 0.9686 - mean_squared_error: 0.0270
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0913 - acc: 0.9685 - mean_squared_error: 0.0270
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0906 - acc: 0.9687 - mean_squared_error: 0.0269
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0899 - acc: 0.9688 - mean_squared_error: 0.0268
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0892 - acc: 0.9688 - mean_squared_error: 0.0268
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0882 - acc: 0.9689 - mean_squared_error: 0.0267
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0888 - acc: 0.9688 - mean_squared_error: 0.0267
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0885 - acc: 0.9689 - mean_squared_error: 0.0266
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0884 - acc: 0.9689 - mean_squared_error: 0.0266
172500/173046 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9690 - mean_squared_error: 0.0266
173046/173046 [==============================] - 2s 11us/step - loss: 0.0883 - acc: 0.9690 - mean_squared_error: 0.0266 - val_loss: 4.2785e-04 - val_acc: 0.9705 - val_mean_squared_error: 0.0251

Epoch 00011: val_loss improved from 0.00046 to 0.00043, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 12/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0415 - acc: 0.9800 - mean_squared_error: 0.0179
  5750/173046 [..............................] - ETA: 1s - loss: 0.1109 - acc: 0.9640 - mean_squared_error: 0.0315
 11500/173046 [>.............................] - ETA: 1s - loss: 0.1044 - acc: 0.9638 - mean_squared_error: 0.0322
 17250/173046 [=>............................] - ETA: 1s - loss: 0.1062 - acc: 0.9653 - mean_squared_error: 0.0301
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.1057 - acc: 0.9657 - mean_squared_error: 0.0293
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.1010 - acc: 0.9657 - mean_squared_error: 0.0294
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.1035 - acc: 0.9659 - mean_squared_error: 0.0293
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.1003 - acc: 0.9669 - mean_squared_error: 0.0284
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0961 - acc: 0.9676 - mean_squared_error: 0.0276
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0947 - acc: 0.9677 - mean_squared_error: 0.0274
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0930 - acc: 0.9680 - mean_squared_error: 0.0272
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0918 - acc: 0.9679 - mean_squared_error: 0.0273
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0915 - acc: 0.9681 - mean_squared_error: 0.0272
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0893 - acc: 0.9679 - mean_squared_error: 0.0273
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0900 - acc: 0.9678 - mean_squared_error: 0.0273
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0907 - acc: 0.9678 - mean_squared_error: 0.0273
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0900 - acc: 0.9679 - mean_squared_error: 0.0272
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0894 - acc: 0.9682 - mean_squared_error: 0.0269
103500/173046 [================>.............] - ETA: 0s - loss: 0.0892 - acc: 0.9685 - mean_squared_error: 0.0267
109250/173046 [=================>............] - ETA: 0s - loss: 0.0893 - acc: 0.9686 - mean_squared_error: 0.0266
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0887 - acc: 0.9689 - mean_squared_error: 0.0264
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0883 - acc: 0.9688 - mean_squared_error: 0.0264
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0889 - acc: 0.9688 - mean_squared_error: 0.0265
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0890 - acc: 0.9688 - mean_squared_error: 0.0265
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0885 - acc: 0.9689 - mean_squared_error: 0.0264
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0885 - acc: 0.9688 - mean_squared_error: 0.0264
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0887 - acc: 0.9687 - mean_squared_error: 0.0265
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0881 - acc: 0.9689 - mean_squared_error: 0.0263
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0878 - acc: 0.9688 - mean_squared_error: 0.0264
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0875 - acc: 0.9689 - mean_squared_error: 0.0263
172500/173046 [============================>.] - ETA: 0s - loss: 0.0879 - acc: 0.9690 - mean_squared_error: 0.0263
173046/173046 [==============================] - 2s 11us/step - loss: 0.0878 - acc: 0.9690 - mean_squared_error: 0.0263 - val_loss: 6.7316e-04 - val_acc: 0.9666 - val_mean_squared_error: 0.0292

Epoch 00012: val_loss did not improve
Epoch 13/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0380 - acc: 0.9600 - mean_squared_error: 0.0334
  6000/173046 [>.............................] - ETA: 1s - loss: 0.0840 - acc: 0.9673 - mean_squared_error: 0.0292
 11750/173046 [=>............................] - ETA: 1s - loss: 0.0845 - acc: 0.9700 - mean_squared_error: 0.0262
 17500/173046 [==>...........................] - ETA: 1s - loss: 0.0881 - acc: 0.9705 - mean_squared_error: 0.0256
 23750/173046 [===>..........................] - ETA: 1s - loss: 0.0862 - acc: 0.9698 - mean_squared_error: 0.0263
 30000/173046 [====>.........................] - ETA: 1s - loss: 0.0854 - acc: 0.9697 - mean_squared_error: 0.0262
 36250/173046 [=====>........................] - ETA: 1s - loss: 0.0854 - acc: 0.9700 - mean_squared_error: 0.0260
 42500/173046 [======>.......................] - ETA: 1s - loss: 0.0846 - acc: 0.9702 - mean_squared_error: 0.0258
 48750/173046 [=======>......................] - ETA: 1s - loss: 0.0824 - acc: 0.9708 - mean_squared_error: 0.0252
 55000/173046 [========>.....................] - ETA: 1s - loss: 0.0824 - acc: 0.9708 - mean_squared_error: 0.0253
 61250/173046 [=========>....................] - ETA: 0s - loss: 0.0854 - acc: 0.9705 - mean_squared_error: 0.0253
 67500/173046 [==========>...................] - ETA: 0s - loss: 0.0851 - acc: 0.9700 - mean_squared_error: 0.0258
 73750/173046 [===========>..................] - ETA: 0s - loss: 0.0875 - acc: 0.9696 - mean_squared_error: 0.0261
 80000/173046 [============>.................] - ETA: 0s - loss: 0.0879 - acc: 0.9697 - mean_squared_error: 0.0259
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0887 - acc: 0.9698 - mean_squared_error: 0.0259
 92500/173046 [===============>..............] - ETA: 0s - loss: 0.0874 - acc: 0.9697 - mean_squared_error: 0.0260
 98750/173046 [================>.............] - ETA: 0s - loss: 0.0865 - acc: 0.9698 - mean_squared_error: 0.0258
105000/173046 [=================>............] - ETA: 0s - loss: 0.0856 - acc: 0.9699 - mean_squared_error: 0.0257
111250/173046 [==================>...........] - ETA: 0s - loss: 0.0850 - acc: 0.9700 - mean_squared_error: 0.0256
117500/173046 [===================>..........] - ETA: 0s - loss: 0.0858 - acc: 0.9699 - mean_squared_error: 0.0257
123750/173046 [====================>.........] - ETA: 0s - loss: 0.0869 - acc: 0.9699 - mean_squared_error: 0.0258
130000/173046 [=====================>........] - ETA: 0s - loss: 0.0863 - acc: 0.9699 - mean_squared_error: 0.0258
136250/173046 [======================>.......] - ETA: 0s - loss: 0.0867 - acc: 0.9700 - mean_squared_error: 0.0257
142500/173046 [=======================>......] - ETA: 0s - loss: 0.0868 - acc: 0.9699 - mean_squared_error: 0.0258
148500/173046 [========================>.....] - ETA: 0s - loss: 0.0860 - acc: 0.9701 - mean_squared_error: 0.0256
154500/173046 [=========================>....] - ETA: 0s - loss: 0.0866 - acc: 0.9700 - mean_squared_error: 0.0257
160500/173046 [==========================>...] - ETA: 0s - loss: 0.0859 - acc: 0.9700 - mean_squared_error: 0.0257
166500/173046 [===========================>..] - ETA: 0s - loss: 0.0849 - acc: 0.9700 - mean_squared_error: 0.0258
172500/173046 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9698 - mean_squared_error: 0.0258
173046/173046 [==============================] - 2s 10us/step - loss: 0.0852 - acc: 0.9698 - mean_squared_error: 0.0258 - val_loss: 9.5138e-04 - val_acc: 0.9626 - val_mean_squared_error: 0.0340

Epoch 00013: val_loss did not improve
Epoch 14/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0925 - acc: 0.9520 - mean_squared_error: 0.0462
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0852 - acc: 0.9677 - mean_squared_error: 0.0279
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0883 - acc: 0.9677 - mean_squared_error: 0.0277
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0866 - acc: 0.9689 - mean_squared_error: 0.0266
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0836 - acc: 0.9693 - mean_squared_error: 0.0263
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0872 - acc: 0.9697 - mean_squared_error: 0.0259
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0882 - acc: 0.9694 - mean_squared_error: 0.0261
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0883 - acc: 0.9690 - mean_squared_error: 0.0267
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0884 - acc: 0.9689 - mean_squared_error: 0.0267
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0867 - acc: 0.9693 - mean_squared_error: 0.0263
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0859 - acc: 0.9693 - mean_squared_error: 0.0264
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0864 - acc: 0.9690 - mean_squared_error: 0.0266
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0856 - acc: 0.9692 - mean_squared_error: 0.0264
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0854 - acc: 0.9692 - mean_squared_error: 0.0264
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0859 - acc: 0.9691 - mean_squared_error: 0.0264
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0862 - acc: 0.9691 - mean_squared_error: 0.0265
100250/173046 [================>.............] - ETA: 0s - loss: 0.0865 - acc: 0.9690 - mean_squared_error: 0.0266
106500/173046 [=================>............] - ETA: 0s - loss: 0.0861 - acc: 0.9691 - mean_squared_error: 0.0264
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0872 - acc: 0.9690 - mean_squared_error: 0.0265
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0872 - acc: 0.9690 - mean_squared_error: 0.0265
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0872 - acc: 0.9690 - mean_squared_error: 0.0265
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0866 - acc: 0.9693 - mean_squared_error: 0.0263
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0864 - acc: 0.9695 - mean_squared_error: 0.0261
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0864 - acc: 0.9695 - mean_squared_error: 0.0261
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0865 - acc: 0.9695 - mean_squared_error: 0.0262
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0870 - acc: 0.9694 - mean_squared_error: 0.0263
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0869 - acc: 0.9696 - mean_squared_error: 0.0261
169000/173046 [============================>.] - ETA: 0s - loss: 0.0865 - acc: 0.9698 - mean_squared_error: 0.0260
173046/173046 [==============================] - 2s 10us/step - loss: 0.0866 - acc: 0.9697 - mean_squared_error: 0.0260 - val_loss: 4.5681e-04 - val_acc: 0.9707 - val_mean_squared_error: 0.0249

Epoch 00014: val_loss did not improve
Epoch 15/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0815 - acc: 0.9800 - mean_squared_error: 0.0174
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0875 - acc: 0.9758 - mean_squared_error: 0.0219
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0840 - acc: 0.9714 - mean_squared_error: 0.0244
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0829 - acc: 0.9718 - mean_squared_error: 0.0243
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0838 - acc: 0.9706 - mean_squared_error: 0.0253
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0843 - acc: 0.9696 - mean_squared_error: 0.0264
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0912 - acc: 0.9685 - mean_squared_error: 0.0272
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0908 - acc: 0.9683 - mean_squared_error: 0.0271
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0920 - acc: 0.9685 - mean_squared_error: 0.0270
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0909 - acc: 0.9689 - mean_squared_error: 0.0267
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0899 - acc: 0.9691 - mean_squared_error: 0.0265
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0892 - acc: 0.9690 - mean_squared_error: 0.0266
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0890 - acc: 0.9693 - mean_squared_error: 0.0264
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0880 - acc: 0.9694 - mean_squared_error: 0.0263
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0867 - acc: 0.9695 - mean_squared_error: 0.0261
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0851 - acc: 0.9696 - mean_squared_error: 0.0261
100250/173046 [================>.............] - ETA: 0s - loss: 0.0840 - acc: 0.9695 - mean_squared_error: 0.0261
106500/173046 [=================>............] - ETA: 0s - loss: 0.0844 - acc: 0.9698 - mean_squared_error: 0.0260
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0847 - acc: 0.9698 - mean_squared_error: 0.0259
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0842 - acc: 0.9698 - mean_squared_error: 0.0259
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0841 - acc: 0.9700 - mean_squared_error: 0.0257
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0842 - acc: 0.9699 - mean_squared_error: 0.0258
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0845 - acc: 0.9700 - mean_squared_error: 0.0258
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0849 - acc: 0.9699 - mean_squared_error: 0.0259
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0850 - acc: 0.9698 - mean_squared_error: 0.0260
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0846 - acc: 0.9697 - mean_squared_error: 0.0260
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0847 - acc: 0.9697 - mean_squared_error: 0.0259
169000/173046 [============================>.] - ETA: 0s - loss: 0.0844 - acc: 0.9698 - mean_squared_error: 0.0259
173046/173046 [==============================] - 2s 10us/step - loss: 0.0843 - acc: 0.9698 - mean_squared_error: 0.0259 - val_loss: 5.5918e-04 - val_acc: 0.9699 - val_mean_squared_error: 0.0262

Epoch 00015: val_loss did not improve
Epoch 16/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1966 - acc: 0.9800 - mean_squared_error: 0.0199
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0655 - acc: 0.9723 - mean_squared_error: 0.0234
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0756 - acc: 0.9707 - mean_squared_error: 0.0245
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0821 - acc: 0.9713 - mean_squared_error: 0.0241
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0808 - acc: 0.9714 - mean_squared_error: 0.0244
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0832 - acc: 0.9702 - mean_squared_error: 0.0253
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0861 - acc: 0.9697 - mean_squared_error: 0.0258
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0866 - acc: 0.9701 - mean_squared_error: 0.0254
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0856 - acc: 0.9704 - mean_squared_error: 0.0252
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0836 - acc: 0.9704 - mean_squared_error: 0.0252
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0838 - acc: 0.9703 - mean_squared_error: 0.0253
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0831 - acc: 0.9707 - mean_squared_error: 0.0250
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0824 - acc: 0.9703 - mean_squared_error: 0.0252
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0833 - acc: 0.9703 - mean_squared_error: 0.0253
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0831 - acc: 0.9701 - mean_squared_error: 0.0255
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0843 - acc: 0.9701 - mean_squared_error: 0.0254
100250/173046 [================>.............] - ETA: 0s - loss: 0.0844 - acc: 0.9701 - mean_squared_error: 0.0254
106500/173046 [=================>............] - ETA: 0s - loss: 0.0835 - acc: 0.9702 - mean_squared_error: 0.0253
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0832 - acc: 0.9702 - mean_squared_error: 0.0253
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0841 - acc: 0.9700 - mean_squared_error: 0.0254
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0849 - acc: 0.9701 - mean_squared_error: 0.0254
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0837 - acc: 0.9702 - mean_squared_error: 0.0254
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0830 - acc: 0.9702 - mean_squared_error: 0.0253
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0837 - acc: 0.9700 - mean_squared_error: 0.0255
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0841 - acc: 0.9700 - mean_squared_error: 0.0256
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0840 - acc: 0.9699 - mean_squared_error: 0.0256
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0837 - acc: 0.9700 - mean_squared_error: 0.0256
169000/173046 [============================>.] - ETA: 0s - loss: 0.0840 - acc: 0.9699 - mean_squared_error: 0.0256
173046/173046 [==============================] - 2s 10us/step - loss: 0.0837 - acc: 0.9699 - mean_squared_error: 0.0256 - val_loss: 4.6989e-04 - val_acc: 0.9705 - val_mean_squared_error: 0.0251

Epoch 00016: val_loss did not improve
Epoch 17/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0341 - acc: 0.9600 - mean_squared_error: 0.0345
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0772 - acc: 0.9700 - mean_squared_error: 0.0253
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0785 - acc: 0.9696 - mean_squared_error: 0.0257
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0778 - acc: 0.9699 - mean_squared_error: 0.0255
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0821 - acc: 0.9704 - mean_squared_error: 0.0252
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0820 - acc: 0.9702 - mean_squared_error: 0.0253
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0837 - acc: 0.9701 - mean_squared_error: 0.0255
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0818 - acc: 0.9704 - mean_squared_error: 0.0251
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0821 - acc: 0.9706 - mean_squared_error: 0.0250
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0807 - acc: 0.9702 - mean_squared_error: 0.0252
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0822 - acc: 0.9699 - mean_squared_error: 0.0255
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0827 - acc: 0.9699 - mean_squared_error: 0.0255
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0826 - acc: 0.9697 - mean_squared_error: 0.0257
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0819 - acc: 0.9698 - mean_squared_error: 0.0256
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0826 - acc: 0.9699 - mean_squared_error: 0.0256
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0830 - acc: 0.9699 - mean_squared_error: 0.0255
100250/173046 [================>.............] - ETA: 0s - loss: 0.0830 - acc: 0.9697 - mean_squared_error: 0.0258
106500/173046 [=================>............] - ETA: 0s - loss: 0.0828 - acc: 0.9697 - mean_squared_error: 0.0257
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0833 - acc: 0.9697 - mean_squared_error: 0.0258
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0829 - acc: 0.9698 - mean_squared_error: 0.0257
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0838 - acc: 0.9699 - mean_squared_error: 0.0256
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0842 - acc: 0.9699 - mean_squared_error: 0.0257
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0839 - acc: 0.9698 - mean_squared_error: 0.0257
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0833 - acc: 0.9699 - mean_squared_error: 0.0256
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0837 - acc: 0.9698 - mean_squared_error: 0.0257
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0829 - acc: 0.9699 - mean_squared_error: 0.0257
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0824 - acc: 0.9699 - mean_squared_error: 0.0257
169000/173046 [============================>.] - ETA: 0s - loss: 0.0833 - acc: 0.9698 - mean_squared_error: 0.0257
173046/173046 [==============================] - 2s 10us/step - loss: 0.0831 - acc: 0.9699 - mean_squared_error: 0.0257 - val_loss: 4.4067e-04 - val_acc: 0.9714 - val_mean_squared_error: 0.0242

Epoch 00017: val_loss did not improve
Epoch 18/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0882 - acc: 0.9680 - mean_squared_error: 0.0286
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0864 - acc: 0.9674 - mean_squared_error: 0.0283
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0860 - acc: 0.9687 - mean_squared_error: 0.0265
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0810 - acc: 0.9696 - mean_squared_error: 0.0261
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0782 - acc: 0.9703 - mean_squared_error: 0.0257
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0751 - acc: 0.9697 - mean_squared_error: 0.0258
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0762 - acc: 0.9695 - mean_squared_error: 0.0261
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0800 - acc: 0.9692 - mean_squared_error: 0.0264
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0824 - acc: 0.9695 - mean_squared_error: 0.0261
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0818 - acc: 0.9695 - mean_squared_error: 0.0261
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0807 - acc: 0.9695 - mean_squared_error: 0.0261
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0820 - acc: 0.9694 - mean_squared_error: 0.0262
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0814 - acc: 0.9697 - mean_squared_error: 0.0260
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0801 - acc: 0.9699 - mean_squared_error: 0.0258
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0809 - acc: 0.9698 - mean_squared_error: 0.0258
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0818 - acc: 0.9698 - mean_squared_error: 0.0257
100250/173046 [================>.............] - ETA: 0s - loss: 0.0818 - acc: 0.9699 - mean_squared_error: 0.0257
106500/173046 [=================>............] - ETA: 0s - loss: 0.0815 - acc: 0.9700 - mean_squared_error: 0.0256
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0835 - acc: 0.9698 - mean_squared_error: 0.0258
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0833 - acc: 0.9696 - mean_squared_error: 0.0259
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0831 - acc: 0.9698 - mean_squared_error: 0.0258
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0839 - acc: 0.9698 - mean_squared_error: 0.0258
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0841 - acc: 0.9697 - mean_squared_error: 0.0258
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0852 - acc: 0.9697 - mean_squared_error: 0.0259
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0851 - acc: 0.9698 - mean_squared_error: 0.0258
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0846 - acc: 0.9699 - mean_squared_error: 0.0257
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0842 - acc: 0.9700 - mean_squared_error: 0.0257
169000/173046 [============================>.] - ETA: 0s - loss: 0.0841 - acc: 0.9700 - mean_squared_error: 0.0256
173046/173046 [==============================] - 2s 10us/step - loss: 0.0837 - acc: 0.9700 - mean_squared_error: 0.0257 - val_loss: 4.1688e-04 - val_acc: 0.9715 - val_mean_squared_error: 0.0243

Epoch 00018: val_loss improved from 0.00043 to 0.00042, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 19/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0777 - acc: 0.9840 - mean_squared_error: 0.0133
  5750/173046 [..............................] - ETA: 1s - loss: 0.1035 - acc: 0.9671 - mean_squared_error: 0.0287
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0832 - acc: 0.9681 - mean_squared_error: 0.0275
 17250/173046 [=>............................] - ETA: 1s - loss: 0.0815 - acc: 0.9686 - mean_squared_error: 0.0271
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.0767 - acc: 0.9697 - mean_squared_error: 0.0262
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.0830 - acc: 0.9701 - mean_squared_error: 0.0261
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.0798 - acc: 0.9702 - mean_squared_error: 0.0260
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.0794 - acc: 0.9701 - mean_squared_error: 0.0260
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0824 - acc: 0.9696 - mean_squared_error: 0.0263
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0810 - acc: 0.9699 - mean_squared_error: 0.0260
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0815 - acc: 0.9697 - mean_squared_error: 0.0261
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0821 - acc: 0.9696 - mean_squared_error: 0.0261
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0807 - acc: 0.9696 - mean_squared_error: 0.0261
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0810 - acc: 0.9694 - mean_squared_error: 0.0262
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0806 - acc: 0.9697 - mean_squared_error: 0.0260
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0830 - acc: 0.9694 - mean_squared_error: 0.0263
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0818 - acc: 0.9696 - mean_squared_error: 0.0261
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0821 - acc: 0.9694 - mean_squared_error: 0.0262
103500/173046 [================>.............] - ETA: 0s - loss: 0.0814 - acc: 0.9695 - mean_squared_error: 0.0262
109250/173046 [=================>............] - ETA: 0s - loss: 0.0804 - acc: 0.9696 - mean_squared_error: 0.0261
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0806 - acc: 0.9698 - mean_squared_error: 0.0259
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0795 - acc: 0.9699 - mean_squared_error: 0.0258
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0811 - acc: 0.9699 - mean_squared_error: 0.0258
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0803 - acc: 0.9699 - mean_squared_error: 0.0258
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0799 - acc: 0.9699 - mean_squared_error: 0.0258
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0804 - acc: 0.9699 - mean_squared_error: 0.0258
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0805 - acc: 0.9699 - mean_squared_error: 0.0257
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0814 - acc: 0.9698 - mean_squared_error: 0.0258
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0818 - acc: 0.9698 - mean_squared_error: 0.0258
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0825 - acc: 0.9698 - mean_squared_error: 0.0258
172500/173046 [============================>.] - ETA: 0s - loss: 0.0831 - acc: 0.9698 - mean_squared_error: 0.0258
173046/173046 [==============================] - 2s 11us/step - loss: 0.0833 - acc: 0.9698 - mean_squared_error: 0.0258 - val_loss: 3.9136e-04 - val_acc: 0.9712 - val_mean_squared_error: 0.0245

Epoch 00019: val_loss improved from 0.00042 to 0.00039, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 20/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0330 - acc: 0.9880 - mean_squared_error: 0.0100
  5750/173046 [..............................] - ETA: 1s - loss: 0.0807 - acc: 0.9708 - mean_squared_error: 0.0246
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0841 - acc: 0.9711 - mean_squared_error: 0.0245
 17250/173046 [=>............................] - ETA: 1s - loss: 0.0887 - acc: 0.9706 - mean_squared_error: 0.0247
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.0821 - acc: 0.9715 - mean_squared_error: 0.0241
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.0818 - acc: 0.9709 - mean_squared_error: 0.0245
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.0814 - acc: 0.9706 - mean_squared_error: 0.0247
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.0805 - acc: 0.9710 - mean_squared_error: 0.0245
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0797 - acc: 0.9708 - mean_squared_error: 0.0246
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0801 - acc: 0.9709 - mean_squared_error: 0.0245
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0817 - acc: 0.9708 - mean_squared_error: 0.0247
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0793 - acc: 0.9707 - mean_squared_error: 0.0249
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0785 - acc: 0.9706 - mean_squared_error: 0.0250
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0786 - acc: 0.9705 - mean_squared_error: 0.0251
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0788 - acc: 0.9703 - mean_squared_error: 0.0253
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0796 - acc: 0.9704 - mean_squared_error: 0.0253
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0783 - acc: 0.9707 - mean_squared_error: 0.0251
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0785 - acc: 0.9708 - mean_squared_error: 0.0251
103500/173046 [================>.............] - ETA: 0s - loss: 0.0786 - acc: 0.9707 - mean_squared_error: 0.0251
109250/173046 [=================>............] - ETA: 0s - loss: 0.0790 - acc: 0.9707 - mean_squared_error: 0.0251
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0794 - acc: 0.9706 - mean_squared_error: 0.0252
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0790 - acc: 0.9707 - mean_squared_error: 0.0251
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0798 - acc: 0.9706 - mean_squared_error: 0.0252
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0794 - acc: 0.9705 - mean_squared_error: 0.0252
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0808 - acc: 0.9704 - mean_squared_error: 0.0253
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0811 - acc: 0.9704 - mean_squared_error: 0.0253
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0809 - acc: 0.9704 - mean_squared_error: 0.0253
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0816 - acc: 0.9704 - mean_squared_error: 0.0253
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0810 - acc: 0.9704 - mean_squared_error: 0.0253
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0815 - acc: 0.9703 - mean_squared_error: 0.0254
172500/173046 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9702 - mean_squared_error: 0.0255
173046/173046 [==============================] - 2s 11us/step - loss: 0.0824 - acc: 0.9702 - mean_squared_error: 0.0255 - val_loss: 4.9266e-04 - val_acc: 0.9703 - val_mean_squared_error: 0.0256

Epoch 00020: val_loss did not improve
Epoch 21/50

   250/173046 [..............................] - ETA: 5s - loss: 0.1268 - acc: 0.9640 - mean_squared_error: 0.0301
  6000/173046 [>.............................] - ETA: 1s - loss: 0.0686 - acc: 0.9703 - mean_squared_error: 0.0251
 11750/173046 [=>............................] - ETA: 1s - loss: 0.0761 - acc: 0.9713 - mean_squared_error: 0.0246
 17500/173046 [==>...........................] - ETA: 1s - loss: 0.0768 - acc: 0.9716 - mean_squared_error: 0.0246
 23750/173046 [===>..........................] - ETA: 1s - loss: 0.0754 - acc: 0.9712 - mean_squared_error: 0.0248
 30000/173046 [====>.........................] - ETA: 1s - loss: 0.0781 - acc: 0.9714 - mean_squared_error: 0.0246
 36250/173046 [=====>........................] - ETA: 1s - loss: 0.0785 - acc: 0.9714 - mean_squared_error: 0.0246
 42500/173046 [======>.......................] - ETA: 1s - loss: 0.0761 - acc: 0.9713 - mean_squared_error: 0.0248
 48750/173046 [=======>......................] - ETA: 1s - loss: 0.0767 - acc: 0.9715 - mean_squared_error: 0.0246
 55000/173046 [========>.....................] - ETA: 1s - loss: 0.0747 - acc: 0.9715 - mean_squared_error: 0.0243
 61250/173046 [=========>....................] - ETA: 0s - loss: 0.0766 - acc: 0.9712 - mean_squared_error: 0.0245
 67500/173046 [==========>...................] - ETA: 0s - loss: 0.0775 - acc: 0.9707 - mean_squared_error: 0.0250
 73750/173046 [===========>..................] - ETA: 0s - loss: 0.0783 - acc: 0.9705 - mean_squared_error: 0.0250
 80000/173046 [============>.................] - ETA: 0s - loss: 0.0781 - acc: 0.9706 - mean_squared_error: 0.0250
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0800 - acc: 0.9706 - mean_squared_error: 0.0251
 92500/173046 [===============>..............] - ETA: 0s - loss: 0.0804 - acc: 0.9706 - mean_squared_error: 0.0250
 98750/173046 [================>.............] - ETA: 0s - loss: 0.0799 - acc: 0.9707 - mean_squared_error: 0.0250
105000/173046 [=================>............] - ETA: 0s - loss: 0.0801 - acc: 0.9710 - mean_squared_error: 0.0247
111250/173046 [==================>...........] - ETA: 0s - loss: 0.0797 - acc: 0.9709 - mean_squared_error: 0.0247
117500/173046 [===================>..........] - ETA: 0s - loss: 0.0804 - acc: 0.9707 - mean_squared_error: 0.0249
123750/173046 [====================>.........] - ETA: 0s - loss: 0.0813 - acc: 0.9705 - mean_squared_error: 0.0251
130000/173046 [=====================>........] - ETA: 0s - loss: 0.0819 - acc: 0.9704 - mean_squared_error: 0.0252
136250/173046 [======================>.......] - ETA: 0s - loss: 0.0820 - acc: 0.9704 - mean_squared_error: 0.0252
142500/173046 [=======================>......] - ETA: 0s - loss: 0.0815 - acc: 0.9703 - mean_squared_error: 0.0253
148750/173046 [========================>.....] - ETA: 0s - loss: 0.0819 - acc: 0.9702 - mean_squared_error: 0.0254
155000/173046 [=========================>....] - ETA: 0s - loss: 0.0819 - acc: 0.9701 - mean_squared_error: 0.0255
161250/173046 [==========================>...] - ETA: 0s - loss: 0.0828 - acc: 0.9699 - mean_squared_error: 0.0257
167500/173046 [============================>.] - ETA: 0s - loss: 0.0824 - acc: 0.9700 - mean_squared_error: 0.0256
173046/173046 [==============================] - 2s 10us/step - loss: 0.0824 - acc: 0.9700 - mean_squared_error: 0.0255 - val_loss: 5.1679e-04 - val_acc: 0.9704 - val_mean_squared_error: 0.0256

Epoch 00021: val_loss did not improve
Epoch 22/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0697 - acc: 0.9600 - mean_squared_error: 0.0367
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0727 - acc: 0.9732 - mean_squared_error: 0.0227
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0792 - acc: 0.9714 - mean_squared_error: 0.0245
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0727 - acc: 0.9707 - mean_squared_error: 0.0250
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0773 - acc: 0.9711 - mean_squared_error: 0.0249
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0758 - acc: 0.9714 - mean_squared_error: 0.0245
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0755 - acc: 0.9713 - mean_squared_error: 0.0246
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0755 - acc: 0.9713 - mean_squared_error: 0.0246
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0756 - acc: 0.9713 - mean_squared_error: 0.0246
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0774 - acc: 0.9708 - mean_squared_error: 0.0250
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0778 - acc: 0.9706 - mean_squared_error: 0.0251
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0768 - acc: 0.9706 - mean_squared_error: 0.0251
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0779 - acc: 0.9706 - mean_squared_error: 0.0251
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0773 - acc: 0.9707 - mean_squared_error: 0.0251
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0790 - acc: 0.9707 - mean_squared_error: 0.0251
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0797 - acc: 0.9704 - mean_squared_error: 0.0253
100250/173046 [================>.............] - ETA: 0s - loss: 0.0794 - acc: 0.9704 - mean_squared_error: 0.0253
106500/173046 [=================>............] - ETA: 0s - loss: 0.0798 - acc: 0.9706 - mean_squared_error: 0.0252
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0796 - acc: 0.9705 - mean_squared_error: 0.0252
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0788 - acc: 0.9706 - mean_squared_error: 0.0252
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0783 - acc: 0.9707 - mean_squared_error: 0.0251
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0783 - acc: 0.9705 - mean_squared_error: 0.0252
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0786 - acc: 0.9706 - mean_squared_error: 0.0252
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0795 - acc: 0.9706 - mean_squared_error: 0.0251
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0795 - acc: 0.9705 - mean_squared_error: 0.0252
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0795 - acc: 0.9706 - mean_squared_error: 0.0251
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0798 - acc: 0.9707 - mean_squared_error: 0.0250
169000/173046 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9705 - mean_squared_error: 0.0252
173046/173046 [==============================] - 2s 10us/step - loss: 0.0801 - acc: 0.9706 - mean_squared_error: 0.0252 - val_loss: 4.5407e-04 - val_acc: 0.9708 - val_mean_squared_error: 0.0249

Epoch 00022: val_loss did not improve
Epoch 23/50

   250/173046 [..............................] - ETA: 5s - loss: 0.1085 - acc: 0.9840 - mean_squared_error: 0.0126
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0903 - acc: 0.9662 - mean_squared_error: 0.0284
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0917 - acc: 0.9674 - mean_squared_error: 0.0273
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0869 - acc: 0.9681 - mean_squared_error: 0.0268
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0834 - acc: 0.9690 - mean_squared_error: 0.0260
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0833 - acc: 0.9695 - mean_squared_error: 0.0257
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0817 - acc: 0.9701 - mean_squared_error: 0.0254
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0804 - acc: 0.9704 - mean_squared_error: 0.0251
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0817 - acc: 0.9700 - mean_squared_error: 0.0254
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0822 - acc: 0.9695 - mean_squared_error: 0.0257
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0863 - acc: 0.9692 - mean_squared_error: 0.0259
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0865 - acc: 0.9695 - mean_squared_error: 0.0257
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0859 - acc: 0.9697 - mean_squared_error: 0.0256
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0853 - acc: 0.9700 - mean_squared_error: 0.0253
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0838 - acc: 0.9703 - mean_squared_error: 0.0252
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0836 - acc: 0.9703 - mean_squared_error: 0.0252
100250/173046 [================>.............] - ETA: 0s - loss: 0.0836 - acc: 0.9700 - mean_squared_error: 0.0254
106500/173046 [=================>............] - ETA: 0s - loss: 0.0831 - acc: 0.9698 - mean_squared_error: 0.0256
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0841 - acc: 0.9696 - mean_squared_error: 0.0258
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0839 - acc: 0.9697 - mean_squared_error: 0.0257
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0829 - acc: 0.9698 - mean_squared_error: 0.0256
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0827 - acc: 0.9698 - mean_squared_error: 0.0256
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0833 - acc: 0.9697 - mean_squared_error: 0.0257
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0835 - acc: 0.9697 - mean_squared_error: 0.0257
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0838 - acc: 0.9697 - mean_squared_error: 0.0257
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0831 - acc: 0.9696 - mean_squared_error: 0.0258
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0825 - acc: 0.9696 - mean_squared_error: 0.0258
169000/173046 [============================>.] - ETA: 0s - loss: 0.0827 - acc: 0.9696 - mean_squared_error: 0.0258
173046/173046 [==============================] - 2s 10us/step - loss: 0.0826 - acc: 0.9697 - mean_squared_error: 0.0258 - val_loss: 4.7548e-04 - val_acc: 0.9706 - val_mean_squared_error: 0.0252

Epoch 00023: val_loss did not improve
Epoch 24/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0351 - acc: 0.9760 - mean_squared_error: 0.0210
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0989 - acc: 0.9720 - mean_squared_error: 0.0237
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0898 - acc: 0.9707 - mean_squared_error: 0.0249
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0820 - acc: 0.9711 - mean_squared_error: 0.0244
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0803 - acc: 0.9707 - mean_squared_error: 0.0250
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0773 - acc: 0.9703 - mean_squared_error: 0.0254
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0785 - acc: 0.9701 - mean_squared_error: 0.0256
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0793 - acc: 0.9701 - mean_squared_error: 0.0255
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0781 - acc: 0.9698 - mean_squared_error: 0.0258
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0784 - acc: 0.9696 - mean_squared_error: 0.0259
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0765 - acc: 0.9695 - mean_squared_error: 0.0259
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0771 - acc: 0.9696 - mean_squared_error: 0.0258
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0783 - acc: 0.9695 - mean_squared_error: 0.0259
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0775 - acc: 0.9695 - mean_squared_error: 0.0259
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0779 - acc: 0.9696 - mean_squared_error: 0.0258
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0782 - acc: 0.9697 - mean_squared_error: 0.0257
100250/173046 [================>.............] - ETA: 0s - loss: 0.0787 - acc: 0.9699 - mean_squared_error: 0.0255
106500/173046 [=================>............] - ETA: 0s - loss: 0.0793 - acc: 0.9700 - mean_squared_error: 0.0255
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0795 - acc: 0.9699 - mean_squared_error: 0.0256
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0792 - acc: 0.9700 - mean_squared_error: 0.0255
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0795 - acc: 0.9701 - mean_squared_error: 0.0254
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0796 - acc: 0.9701 - mean_squared_error: 0.0255
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0800 - acc: 0.9701 - mean_squared_error: 0.0255
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0809 - acc: 0.9701 - mean_squared_error: 0.0254
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0812 - acc: 0.9702 - mean_squared_error: 0.0254
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0814 - acc: 0.9703 - mean_squared_error: 0.0254
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0809 - acc: 0.9703 - mean_squared_error: 0.0254
169000/173046 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9703 - mean_squared_error: 0.0254
173046/173046 [==============================] - 2s 10us/step - loss: 0.0814 - acc: 0.9703 - mean_squared_error: 0.0254 - val_loss: 5.3378e-04 - val_acc: 0.9691 - val_mean_squared_error: 0.0265

Epoch 00024: val_loss did not improve
Epoch 25/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0267 - acc: 0.9840 - mean_squared_error: 0.0132
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0725 - acc: 0.9702 - mean_squared_error: 0.0254
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0745 - acc: 0.9686 - mean_squared_error: 0.0267
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0765 - acc: 0.9698 - mean_squared_error: 0.0259
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0795 - acc: 0.9691 - mean_squared_error: 0.0262
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0832 - acc: 0.9687 - mean_squared_error: 0.0265
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0822 - acc: 0.9692 - mean_squared_error: 0.0262
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0807 - acc: 0.9695 - mean_squared_error: 0.0260
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0793 - acc: 0.9700 - mean_squared_error: 0.0256
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0814 - acc: 0.9696 - mean_squared_error: 0.0258
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0815 - acc: 0.9700 - mean_squared_error: 0.0255
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0806 - acc: 0.9703 - mean_squared_error: 0.0252
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0817 - acc: 0.9703 - mean_squared_error: 0.0252
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0801 - acc: 0.9706 - mean_squared_error: 0.0250
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0794 - acc: 0.9706 - mean_squared_error: 0.0250
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0784 - acc: 0.9708 - mean_squared_error: 0.0248
100250/173046 [================>.............] - ETA: 0s - loss: 0.0780 - acc: 0.9710 - mean_squared_error: 0.0247
106500/173046 [=================>............] - ETA: 0s - loss: 0.0776 - acc: 0.9707 - mean_squared_error: 0.0249
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0775 - acc: 0.9708 - mean_squared_error: 0.0248
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0784 - acc: 0.9707 - mean_squared_error: 0.0249
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0793 - acc: 0.9706 - mean_squared_error: 0.0250
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0798 - acc: 0.9704 - mean_squared_error: 0.0252
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0798 - acc: 0.9704 - mean_squared_error: 0.0252
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0799 - acc: 0.9703 - mean_squared_error: 0.0252
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0799 - acc: 0.9704 - mean_squared_error: 0.0251
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0811 - acc: 0.9704 - mean_squared_error: 0.0252
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0809 - acc: 0.9704 - mean_squared_error: 0.0251
169000/173046 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9705 - mean_squared_error: 0.0251
173046/173046 [==============================] - 2s 10us/step - loss: 0.0805 - acc: 0.9705 - mean_squared_error: 0.0251 - val_loss: 5.1027e-04 - val_acc: 0.9703 - val_mean_squared_error: 0.0255

Epoch 00025: val_loss did not improve
Epoch 26/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1740 - acc: 0.9800 - mean_squared_error: 0.0183
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0909 - acc: 0.9717 - mean_squared_error: 0.0233
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0766 - acc: 0.9734 - mean_squared_error: 0.0223
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0727 - acc: 0.9729 - mean_squared_error: 0.0227
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0715 - acc: 0.9717 - mean_squared_error: 0.0239
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0740 - acc: 0.9714 - mean_squared_error: 0.0241
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0744 - acc: 0.9716 - mean_squared_error: 0.0239
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0751 - acc: 0.9715 - mean_squared_error: 0.0240
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0751 - acc: 0.9711 - mean_squared_error: 0.0244
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0773 - acc: 0.9710 - mean_squared_error: 0.0245
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0799 - acc: 0.9709 - mean_squared_error: 0.0247
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0802 - acc: 0.9710 - mean_squared_error: 0.0246
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0807 - acc: 0.9708 - mean_squared_error: 0.0247
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0795 - acc: 0.9707 - mean_squared_error: 0.0249
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0804 - acc: 0.9706 - mean_squared_error: 0.0250
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0804 - acc: 0.9708 - mean_squared_error: 0.0249
100250/173046 [================>.............] - ETA: 0s - loss: 0.0820 - acc: 0.9705 - mean_squared_error: 0.0251
106500/173046 [=================>............] - ETA: 0s - loss: 0.0819 - acc: 0.9704 - mean_squared_error: 0.0252
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0817 - acc: 0.9701 - mean_squared_error: 0.0254
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0812 - acc: 0.9701 - mean_squared_error: 0.0254
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0814 - acc: 0.9703 - mean_squared_error: 0.0253
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0819 - acc: 0.9702 - mean_squared_error: 0.0254
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0811 - acc: 0.9701 - mean_squared_error: 0.0254
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0805 - acc: 0.9701 - mean_squared_error: 0.0254
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0811 - acc: 0.9701 - mean_squared_error: 0.0255
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0815 - acc: 0.9700 - mean_squared_error: 0.0255
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0813 - acc: 0.9700 - mean_squared_error: 0.0255
169000/173046 [============================>.] - ETA: 0s - loss: 0.0813 - acc: 0.9700 - mean_squared_error: 0.0255
173046/173046 [==============================] - 2s 10us/step - loss: 0.0811 - acc: 0.9701 - mean_squared_error: 0.0254 - val_loss: 4.3051e-04 - val_acc: 0.9713 - val_mean_squared_error: 0.0246

Epoch 00026: val_loss did not improve
Epoch 27/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0907 - acc: 0.9760 - mean_squared_error: 0.0241
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0718 - acc: 0.9735 - mean_squared_error: 0.0236
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0707 - acc: 0.9713 - mean_squared_error: 0.0249
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0702 - acc: 0.9701 - mean_squared_error: 0.0261
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0734 - acc: 0.9705 - mean_squared_error: 0.0255
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0748 - acc: 0.9706 - mean_squared_error: 0.0255
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0748 - acc: 0.9711 - mean_squared_error: 0.0250
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0767 - acc: 0.9710 - mean_squared_error: 0.0251
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0770 - acc: 0.9707 - mean_squared_error: 0.0253
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0762 - acc: 0.9710 - mean_squared_error: 0.0250
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0752 - acc: 0.9711 - mean_squared_error: 0.0249
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0778 - acc: 0.9706 - mean_squared_error: 0.0252
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0780 - acc: 0.9711 - mean_squared_error: 0.0248
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0777 - acc: 0.9711 - mean_squared_error: 0.0248
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0786 - acc: 0.9708 - mean_squared_error: 0.0250
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0788 - acc: 0.9711 - mean_squared_error: 0.0248
100250/173046 [================>.............] - ETA: 0s - loss: 0.0787 - acc: 0.9711 - mean_squared_error: 0.0248
106500/173046 [=================>............] - ETA: 0s - loss: 0.0788 - acc: 0.9710 - mean_squared_error: 0.0248
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0787 - acc: 0.9710 - mean_squared_error: 0.0247
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0789 - acc: 0.9711 - mean_squared_error: 0.0246
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0784 - acc: 0.9711 - mean_squared_error: 0.0246
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0786 - acc: 0.9713 - mean_squared_error: 0.0246
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0793 - acc: 0.9711 - mean_squared_error: 0.0247
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0790 - acc: 0.9710 - mean_squared_error: 0.0247
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0793 - acc: 0.9709 - mean_squared_error: 0.0248
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0794 - acc: 0.9709 - mean_squared_error: 0.0248
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0789 - acc: 0.9709 - mean_squared_error: 0.0249
169000/173046 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9708 - mean_squared_error: 0.0250
173046/173046 [==============================] - 2s 10us/step - loss: 0.0793 - acc: 0.9708 - mean_squared_error: 0.0250 - val_loss: 3.6382e-04 - val_acc: 0.9709 - val_mean_squared_error: 0.0244

Epoch 00027: val_loss improved from 0.00039 to 0.00036, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 28/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0718 - acc: 0.9600 - mean_squared_error: 0.0337
  5750/173046 [..............................] - ETA: 1s - loss: 0.0793 - acc: 0.9729 - mean_squared_error: 0.0227
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0865 - acc: 0.9719 - mean_squared_error: 0.0240
 17250/173046 [=>............................] - ETA: 1s - loss: 0.0833 - acc: 0.9723 - mean_squared_error: 0.0237
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.0861 - acc: 0.9717 - mean_squared_error: 0.0243
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.0839 - acc: 0.9709 - mean_squared_error: 0.0251
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.0831 - acc: 0.9710 - mean_squared_error: 0.0251
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.0845 - acc: 0.9709 - mean_squared_error: 0.0250
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0841 - acc: 0.9708 - mean_squared_error: 0.0250
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0836 - acc: 0.9703 - mean_squared_error: 0.0256
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0825 - acc: 0.9703 - mean_squared_error: 0.0255
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0833 - acc: 0.9704 - mean_squared_error: 0.0254
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0824 - acc: 0.9705 - mean_squared_error: 0.0253
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0843 - acc: 0.9704 - mean_squared_error: 0.0254
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0835 - acc: 0.9704 - mean_squared_error: 0.0254
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0827 - acc: 0.9703 - mean_squared_error: 0.0254
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0832 - acc: 0.9702 - mean_squared_error: 0.0254
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0825 - acc: 0.9701 - mean_squared_error: 0.0255
103500/173046 [================>.............] - ETA: 0s - loss: 0.0827 - acc: 0.9700 - mean_squared_error: 0.0256
109250/173046 [=================>............] - ETA: 0s - loss: 0.0824 - acc: 0.9701 - mean_squared_error: 0.0255
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0817 - acc: 0.9700 - mean_squared_error: 0.0256
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0818 - acc: 0.9699 - mean_squared_error: 0.0257
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0810 - acc: 0.9700 - mean_squared_error: 0.0256
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0817 - acc: 0.9702 - mean_squared_error: 0.0255
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0812 - acc: 0.9704 - mean_squared_error: 0.0253
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0820 - acc: 0.9703 - mean_squared_error: 0.0254
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0810 - acc: 0.9703 - mean_squared_error: 0.0253
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0810 - acc: 0.9703 - mean_squared_error: 0.0253
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0805 - acc: 0.9705 - mean_squared_error: 0.0252
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0804 - acc: 0.9705 - mean_squared_error: 0.0252
172500/173046 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9705 - mean_squared_error: 0.0251
173046/173046 [==============================] - 2s 11us/step - loss: 0.0800 - acc: 0.9706 - mean_squared_error: 0.0251 - val_loss: 4.8383e-04 - val_acc: 0.9706 - val_mean_squared_error: 0.0251

Epoch 00028: val_loss did not improve
Epoch 29/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0330 - acc: 0.9680 - mean_squared_error: 0.0301
  6000/173046 [>.............................] - ETA: 1s - loss: 0.0748 - acc: 0.9688 - mean_squared_error: 0.0269
 11750/173046 [=>............................] - ETA: 1s - loss: 0.0686 - acc: 0.9698 - mean_squared_error: 0.0261
 17500/173046 [==>...........................] - ETA: 1s - loss: 0.0740 - acc: 0.9698 - mean_squared_error: 0.0259
 23750/173046 [===>..........................] - ETA: 1s - loss: 0.0755 - acc: 0.9701 - mean_squared_error: 0.0257
 30000/173046 [====>.........................] - ETA: 1s - loss: 0.0742 - acc: 0.9699 - mean_squared_error: 0.0256
 36250/173046 [=====>........................] - ETA: 1s - loss: 0.0721 - acc: 0.9695 - mean_squared_error: 0.0259
 42500/173046 [======>.......................] - ETA: 1s - loss: 0.0749 - acc: 0.9692 - mean_squared_error: 0.0261
 48750/173046 [=======>......................] - ETA: 1s - loss: 0.0746 - acc: 0.9700 - mean_squared_error: 0.0256
 55000/173046 [========>.....................] - ETA: 1s - loss: 0.0751 - acc: 0.9697 - mean_squared_error: 0.0258
 61250/173046 [=========>....................] - ETA: 0s - loss: 0.0740 - acc: 0.9700 - mean_squared_error: 0.0257
 67500/173046 [==========>...................] - ETA: 0s - loss: 0.0738 - acc: 0.9703 - mean_squared_error: 0.0254
 73750/173046 [===========>..................] - ETA: 0s - loss: 0.0750 - acc: 0.9702 - mean_squared_error: 0.0254
 80000/173046 [============>.................] - ETA: 0s - loss: 0.0761 - acc: 0.9701 - mean_squared_error: 0.0254
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0782 - acc: 0.9700 - mean_squared_error: 0.0255
 92500/173046 [===============>..............] - ETA: 0s - loss: 0.0775 - acc: 0.9700 - mean_squared_error: 0.0255
 98750/173046 [================>.............] - ETA: 0s - loss: 0.0777 - acc: 0.9701 - mean_squared_error: 0.0255
105000/173046 [=================>............] - ETA: 0s - loss: 0.0781 - acc: 0.9699 - mean_squared_error: 0.0255
111250/173046 [==================>...........] - ETA: 0s - loss: 0.0783 - acc: 0.9699 - mean_squared_error: 0.0255
117500/173046 [===================>..........] - ETA: 0s - loss: 0.0774 - acc: 0.9701 - mean_squared_error: 0.0253
123750/173046 [====================>.........] - ETA: 0s - loss: 0.0776 - acc: 0.9702 - mean_squared_error: 0.0252
130000/173046 [=====================>........] - ETA: 0s - loss: 0.0773 - acc: 0.9701 - mean_squared_error: 0.0252
136250/173046 [======================>.......] - ETA: 0s - loss: 0.0782 - acc: 0.9700 - mean_squared_error: 0.0253
142500/173046 [=======================>......] - ETA: 0s - loss: 0.0783 - acc: 0.9700 - mean_squared_error: 0.0253
148750/173046 [========================>.....] - ETA: 0s - loss: 0.0797 - acc: 0.9699 - mean_squared_error: 0.0254
155000/173046 [=========================>....] - ETA: 0s - loss: 0.0797 - acc: 0.9699 - mean_squared_error: 0.0254
161250/173046 [==========================>...] - ETA: 0s - loss: 0.0798 - acc: 0.9700 - mean_squared_error: 0.0254
167500/173046 [============================>.] - ETA: 0s - loss: 0.0795 - acc: 0.9700 - mean_squared_error: 0.0254
173046/173046 [==============================] - 2s 10us/step - loss: 0.0799 - acc: 0.9700 - mean_squared_error: 0.0254 - val_loss: 4.8084e-04 - val_acc: 0.9697 - val_mean_squared_error: 0.0258

Epoch 00029: val_loss did not improve
Epoch 30/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0288 - acc: 0.9880 - mean_squared_error: 0.0145
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0870 - acc: 0.9732 - mean_squared_error: 0.0231
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0832 - acc: 0.9731 - mean_squared_error: 0.0230
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0811 - acc: 0.9722 - mean_squared_error: 0.0233
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0801 - acc: 0.9719 - mean_squared_error: 0.0237
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0830 - acc: 0.9717 - mean_squared_error: 0.0241
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0820 - acc: 0.9719 - mean_squared_error: 0.0239
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0814 - acc: 0.9717 - mean_squared_error: 0.0243
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0789 - acc: 0.9709 - mean_squared_error: 0.0250
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0793 - acc: 0.9710 - mean_squared_error: 0.0249
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0798 - acc: 0.9713 - mean_squared_error: 0.0247
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0807 - acc: 0.9712 - mean_squared_error: 0.0248
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0803 - acc: 0.9709 - mean_squared_error: 0.0250
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0803 - acc: 0.9706 - mean_squared_error: 0.0252
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0805 - acc: 0.9706 - mean_squared_error: 0.0252
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0799 - acc: 0.9705 - mean_squared_error: 0.0252
100250/173046 [================>.............] - ETA: 0s - loss: 0.0798 - acc: 0.9706 - mean_squared_error: 0.0252
106500/173046 [=================>............] - ETA: 0s - loss: 0.0792 - acc: 0.9707 - mean_squared_error: 0.0251
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0794 - acc: 0.9707 - mean_squared_error: 0.0251
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0794 - acc: 0.9707 - mean_squared_error: 0.0251
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0792 - acc: 0.9707 - mean_squared_error: 0.0251
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0798 - acc: 0.9708 - mean_squared_error: 0.0249
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0796 - acc: 0.9707 - mean_squared_error: 0.0250
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0792 - acc: 0.9708 - mean_squared_error: 0.0250
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0792 - acc: 0.9707 - mean_squared_error: 0.0250
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0793 - acc: 0.9709 - mean_squared_error: 0.0249
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0793 - acc: 0.9709 - mean_squared_error: 0.0249
169000/173046 [============================>.] - ETA: 0s - loss: 0.0792 - acc: 0.9708 - mean_squared_error: 0.0250
173046/173046 [==============================] - 2s 10us/step - loss: 0.0792 - acc: 0.9707 - mean_squared_error: 0.0250 - val_loss: 4.2415e-04 - val_acc: 0.9711 - val_mean_squared_error: 0.0245

Epoch 00030: val_loss did not improve
Epoch 31/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0468 - acc: 0.9520 - mean_squared_error: 0.0391
  6500/173046 [>.............................] - ETA: 1s - loss: 0.1059 - acc: 0.9702 - mean_squared_error: 0.0258
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0856 - acc: 0.9732 - mean_squared_error: 0.0235
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0867 - acc: 0.9724 - mean_squared_error: 0.0238
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0860 - acc: 0.9713 - mean_squared_error: 0.0245
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0825 - acc: 0.9715 - mean_squared_error: 0.0244
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0805 - acc: 0.9719 - mean_squared_error: 0.0241
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0794 - acc: 0.9718 - mean_squared_error: 0.0242
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0797 - acc: 0.9717 - mean_squared_error: 0.0242
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0798 - acc: 0.9710 - mean_squared_error: 0.0246
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0806 - acc: 0.9711 - mean_squared_error: 0.0245
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0810 - acc: 0.9712 - mean_squared_error: 0.0245
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0806 - acc: 0.9717 - mean_squared_error: 0.0241
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0783 - acc: 0.9717 - mean_squared_error: 0.0241
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0795 - acc: 0.9714 - mean_squared_error: 0.0243
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0791 - acc: 0.9711 - mean_squared_error: 0.0245
100250/173046 [================>.............] - ETA: 0s - loss: 0.0792 - acc: 0.9709 - mean_squared_error: 0.0247
106500/173046 [=================>............] - ETA: 0s - loss: 0.0780 - acc: 0.9708 - mean_squared_error: 0.0246
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0781 - acc: 0.9708 - mean_squared_error: 0.0247
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0786 - acc: 0.9707 - mean_squared_error: 0.0247
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0780 - acc: 0.9706 - mean_squared_error: 0.0248
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0775 - acc: 0.9705 - mean_squared_error: 0.0249
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0777 - acc: 0.9704 - mean_squared_error: 0.0249
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0774 - acc: 0.9704 - mean_squared_error: 0.0249
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0783 - acc: 0.9704 - mean_squared_error: 0.0249
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0779 - acc: 0.9705 - mean_squared_error: 0.0249
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0780 - acc: 0.9704 - mean_squared_error: 0.0250
169000/173046 [============================>.] - ETA: 0s - loss: 0.0781 - acc: 0.9704 - mean_squared_error: 0.0250
172250/173046 [============================>.] - ETA: 0s - loss: 0.0782 - acc: 0.9704 - mean_squared_error: 0.0250
173046/173046 [==============================] - 2s 10us/step - loss: 0.0783 - acc: 0.9704 - mean_squared_error: 0.0250 - val_loss: 4.4953e-04 - val_acc: 0.9707 - val_mean_squared_error: 0.0249

Epoch 00031: val_loss did not improve
Epoch 32/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0212 - acc: 0.9920 - mean_squared_error: 0.0063
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0626 - acc: 0.9717 - mean_squared_error: 0.0240
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0641 - acc: 0.9731 - mean_squared_error: 0.0234
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0659 - acc: 0.9728 - mean_squared_error: 0.0235
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0716 - acc: 0.9717 - mean_squared_error: 0.0242
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0730 - acc: 0.9717 - mean_squared_error: 0.0241
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0731 - acc: 0.9721 - mean_squared_error: 0.0238
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0719 - acc: 0.9720 - mean_squared_error: 0.0239
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0734 - acc: 0.9718 - mean_squared_error: 0.0241
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0741 - acc: 0.9717 - mean_squared_error: 0.0242
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0745 - acc: 0.9717 - mean_squared_error: 0.0242
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0747 - acc: 0.9719 - mean_squared_error: 0.0240
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0742 - acc: 0.9721 - mean_squared_error: 0.0239
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0741 - acc: 0.9718 - mean_squared_error: 0.0240
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0760 - acc: 0.9716 - mean_squared_error: 0.0242
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0761 - acc: 0.9715 - mean_squared_error: 0.0244
100250/173046 [================>.............] - ETA: 0s - loss: 0.0760 - acc: 0.9711 - mean_squared_error: 0.0246
106250/173046 [=================>............] - ETA: 0s - loss: 0.0761 - acc: 0.9711 - mean_squared_error: 0.0246
112250/173046 [==================>...........] - ETA: 0s - loss: 0.0766 - acc: 0.9709 - mean_squared_error: 0.0248
118250/173046 [===================>..........] - ETA: 0s - loss: 0.0763 - acc: 0.9710 - mean_squared_error: 0.0247
124250/173046 [====================>.........] - ETA: 0s - loss: 0.0773 - acc: 0.9709 - mean_squared_error: 0.0247
130250/173046 [=====================>........] - ETA: 0s - loss: 0.0766 - acc: 0.9710 - mean_squared_error: 0.0246
136250/173046 [======================>.......] - ETA: 0s - loss: 0.0758 - acc: 0.9711 - mean_squared_error: 0.0246
142500/173046 [=======================>......] - ETA: 0s - loss: 0.0761 - acc: 0.9709 - mean_squared_error: 0.0248
148750/173046 [========================>.....] - ETA: 0s - loss: 0.0772 - acc: 0.9708 - mean_squared_error: 0.0248
155000/173046 [=========================>....] - ETA: 0s - loss: 0.0782 - acc: 0.9708 - mean_squared_error: 0.0249
161250/173046 [==========================>...] - ETA: 0s - loss: 0.0788 - acc: 0.9707 - mean_squared_error: 0.0249
167500/173046 [============================>.] - ETA: 0s - loss: 0.0797 - acc: 0.9705 - mean_squared_error: 0.0251
173046/173046 [==============================] - 2s 10us/step - loss: 0.0801 - acc: 0.9705 - mean_squared_error: 0.0251 - val_loss: 3.9531e-04 - val_acc: 0.9714 - val_mean_squared_error: 0.0240

Epoch 00032: val_loss did not improve
Epoch 33/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1140 - acc: 0.9640 - mean_squared_error: 0.0308
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0786 - acc: 0.9714 - mean_squared_error: 0.0244
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0824 - acc: 0.9711 - mean_squared_error: 0.0246
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0719 - acc: 0.9715 - mean_squared_error: 0.0239
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0743 - acc: 0.9700 - mean_squared_error: 0.0248
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0768 - acc: 0.9700 - mean_squared_error: 0.0250
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0754 - acc: 0.9700 - mean_squared_error: 0.0253
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0765 - acc: 0.9708 - mean_squared_error: 0.0247
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0773 - acc: 0.9709 - mean_squared_error: 0.0246
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0783 - acc: 0.9705 - mean_squared_error: 0.0250
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0785 - acc: 0.9705 - mean_squared_error: 0.0249
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0782 - acc: 0.9705 - mean_squared_error: 0.0249
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0771 - acc: 0.9707 - mean_squared_error: 0.0248
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0781 - acc: 0.9706 - mean_squared_error: 0.0250
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0802 - acc: 0.9703 - mean_squared_error: 0.0253
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0802 - acc: 0.9704 - mean_squared_error: 0.0251
100250/173046 [================>.............] - ETA: 0s - loss: 0.0802 - acc: 0.9704 - mean_squared_error: 0.0252
106500/173046 [=================>............] - ETA: 0s - loss: 0.0805 - acc: 0.9705 - mean_squared_error: 0.0252
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0815 - acc: 0.9703 - mean_squared_error: 0.0253
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0812 - acc: 0.9700 - mean_squared_error: 0.0256
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0809 - acc: 0.9700 - mean_squared_error: 0.0256
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0819 - acc: 0.9697 - mean_squared_error: 0.0258
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0817 - acc: 0.9698 - mean_squared_error: 0.0257
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0809 - acc: 0.9700 - mean_squared_error: 0.0256
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0803 - acc: 0.9702 - mean_squared_error: 0.0254
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0799 - acc: 0.9702 - mean_squared_error: 0.0254
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0799 - acc: 0.9703 - mean_squared_error: 0.0254
169000/173046 [============================>.] - ETA: 0s - loss: 0.0800 - acc: 0.9702 - mean_squared_error: 0.0254
173046/173046 [==============================] - 2s 10us/step - loss: 0.0800 - acc: 0.9702 - mean_squared_error: 0.0255 - val_loss: 4.1735e-04 - val_acc: 0.9714 - val_mean_squared_error: 0.0244

Epoch 00033: val_loss did not improve
Epoch 34/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0279 - acc: 0.9800 - mean_squared_error: 0.0205
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0929 - acc: 0.9682 - mean_squared_error: 0.0278
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0839 - acc: 0.9698 - mean_squared_error: 0.0258
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0800 - acc: 0.9693 - mean_squared_error: 0.0262
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0791 - acc: 0.9691 - mean_squared_error: 0.0262
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0784 - acc: 0.9695 - mean_squared_error: 0.0259
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0800 - acc: 0.9703 - mean_squared_error: 0.0254
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0803 - acc: 0.9701 - mean_squared_error: 0.0257
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0792 - acc: 0.9700 - mean_squared_error: 0.0258
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0794 - acc: 0.9704 - mean_squared_error: 0.0254
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0786 - acc: 0.9705 - mean_squared_error: 0.0253
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0793 - acc: 0.9706 - mean_squared_error: 0.0251
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0794 - acc: 0.9708 - mean_squared_error: 0.0249
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0790 - acc: 0.9706 - mean_squared_error: 0.0250
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0795 - acc: 0.9706 - mean_squared_error: 0.0251
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0800 - acc: 0.9707 - mean_squared_error: 0.0250
100250/173046 [================>.............] - ETA: 0s - loss: 0.0800 - acc: 0.9708 - mean_squared_error: 0.0249
106500/173046 [=================>............] - ETA: 0s - loss: 0.0802 - acc: 0.9709 - mean_squared_error: 0.0249
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0801 - acc: 0.9710 - mean_squared_error: 0.0248
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0794 - acc: 0.9710 - mean_squared_error: 0.0248
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0786 - acc: 0.9710 - mean_squared_error: 0.0248
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0796 - acc: 0.9709 - mean_squared_error: 0.0248
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0798 - acc: 0.9710 - mean_squared_error: 0.0248
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0798 - acc: 0.9710 - mean_squared_error: 0.0248
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0806 - acc: 0.9706 - mean_squared_error: 0.0251
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0801 - acc: 0.9708 - mean_squared_error: 0.0250
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0803 - acc: 0.9708 - mean_squared_error: 0.0251
169000/173046 [============================>.] - ETA: 0s - loss: 0.0802 - acc: 0.9708 - mean_squared_error: 0.0250
173046/173046 [==============================] - 2s 10us/step - loss: 0.0803 - acc: 0.9708 - mean_squared_error: 0.0250 - val_loss: 3.6157e-04 - val_acc: 0.9715 - val_mean_squared_error: 0.0239

Epoch 00034: val_loss improved from 0.00036 to 0.00036, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 35/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0445 - acc: 0.9720 - mean_squared_error: 0.0231
  5750/173046 [..............................] - ETA: 1s - loss: 0.0697 - acc: 0.9696 - mean_squared_error: 0.0246
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0678 - acc: 0.9717 - mean_squared_error: 0.0237
 17250/173046 [=>............................] - ETA: 1s - loss: 0.0718 - acc: 0.9717 - mean_squared_error: 0.0241
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.0703 - acc: 0.9717 - mean_squared_error: 0.0242
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.0719 - acc: 0.9713 - mean_squared_error: 0.0243
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.0759 - acc: 0.9708 - mean_squared_error: 0.0249
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.0760 - acc: 0.9708 - mean_squared_error: 0.0250
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0788 - acc: 0.9707 - mean_squared_error: 0.0252
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0786 - acc: 0.9708 - mean_squared_error: 0.0252
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0780 - acc: 0.9710 - mean_squared_error: 0.0249
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0758 - acc: 0.9710 - mean_squared_error: 0.0249
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0769 - acc: 0.9711 - mean_squared_error: 0.0249
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0769 - acc: 0.9713 - mean_squared_error: 0.0245
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0756 - acc: 0.9713 - mean_squared_error: 0.0245
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0772 - acc: 0.9710 - mean_squared_error: 0.0248
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0771 - acc: 0.9707 - mean_squared_error: 0.0250
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0788 - acc: 0.9704 - mean_squared_error: 0.0252
103500/173046 [================>.............] - ETA: 0s - loss: 0.0774 - acc: 0.9704 - mean_squared_error: 0.0252
109250/173046 [=================>............] - ETA: 0s - loss: 0.0765 - acc: 0.9705 - mean_squared_error: 0.0251
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0768 - acc: 0.9706 - mean_squared_error: 0.0250
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0776 - acc: 0.9704 - mean_squared_error: 0.0251
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0787 - acc: 0.9705 - mean_squared_error: 0.0251
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0788 - acc: 0.9705 - mean_squared_error: 0.0251
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0784 - acc: 0.9706 - mean_squared_error: 0.0250
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0781 - acc: 0.9707 - mean_squared_error: 0.0249
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0784 - acc: 0.9708 - mean_squared_error: 0.0248
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0787 - acc: 0.9708 - mean_squared_error: 0.0248
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0791 - acc: 0.9705 - mean_squared_error: 0.0251
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0789 - acc: 0.9706 - mean_squared_error: 0.0250
172500/173046 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9705 - mean_squared_error: 0.0251
173046/173046 [==============================] - 2s 11us/step - loss: 0.0795 - acc: 0.9705 - mean_squared_error: 0.0251 - val_loss: 3.4091e-04 - val_acc: 0.9696 - val_mean_squared_error: 0.0257

Epoch 00035: val_loss improved from 0.00036 to 0.00034, saving model to /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Epoch 36/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0699 - acc: 0.9640 - mean_squared_error: 0.0291
  5750/173046 [..............................] - ETA: 1s - loss: 0.0887 - acc: 0.9699 - mean_squared_error: 0.0246
 11500/173046 [>.............................] - ETA: 1s - loss: 0.0755 - acc: 0.9713 - mean_squared_error: 0.0239
 17250/173046 [=>............................] - ETA: 1s - loss: 0.0780 - acc: 0.9704 - mean_squared_error: 0.0250
 23000/173046 [==>...........................] - ETA: 1s - loss: 0.0772 - acc: 0.9700 - mean_squared_error: 0.0254
 28750/173046 [===>..........................] - ETA: 1s - loss: 0.0759 - acc: 0.9701 - mean_squared_error: 0.0251
 34500/173046 [====>.........................] - ETA: 1s - loss: 0.0768 - acc: 0.9700 - mean_squared_error: 0.0252
 40250/173046 [=====>........................] - ETA: 1s - loss: 0.0791 - acc: 0.9702 - mean_squared_error: 0.0252
 46000/173046 [======>.......................] - ETA: 1s - loss: 0.0795 - acc: 0.9702 - mean_squared_error: 0.0252
 51750/173046 [=======>......................] - ETA: 1s - loss: 0.0809 - acc: 0.9703 - mean_squared_error: 0.0252
 57500/173046 [========>.....................] - ETA: 1s - loss: 0.0802 - acc: 0.9705 - mean_squared_error: 0.0250
 63250/173046 [=========>....................] - ETA: 1s - loss: 0.0800 - acc: 0.9706 - mean_squared_error: 0.0250
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0793 - acc: 0.9707 - mean_squared_error: 0.0250
 74750/173046 [===========>..................] - ETA: 0s - loss: 0.0783 - acc: 0.9707 - mean_squared_error: 0.0248
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0783 - acc: 0.9708 - mean_squared_error: 0.0248
 86250/173046 [=============>................] - ETA: 0s - loss: 0.0788 - acc: 0.9707 - mean_squared_error: 0.0249
 92000/173046 [==============>...............] - ETA: 0s - loss: 0.0787 - acc: 0.9707 - mean_squared_error: 0.0249
 97750/173046 [===============>..............] - ETA: 0s - loss: 0.0784 - acc: 0.9709 - mean_squared_error: 0.0248
103500/173046 [================>.............] - ETA: 0s - loss: 0.0780 - acc: 0.9710 - mean_squared_error: 0.0247
109250/173046 [=================>............] - ETA: 0s - loss: 0.0775 - acc: 0.9712 - mean_squared_error: 0.0246
115000/173046 [==================>...........] - ETA: 0s - loss: 0.0778 - acc: 0.9710 - mean_squared_error: 0.0247
120750/173046 [===================>..........] - ETA: 0s - loss: 0.0773 - acc: 0.9710 - mean_squared_error: 0.0247
126500/173046 [====================>.........] - ETA: 0s - loss: 0.0774 - acc: 0.9710 - mean_squared_error: 0.0246
132250/173046 [=====================>........] - ETA: 0s - loss: 0.0776 - acc: 0.9710 - mean_squared_error: 0.0247
138000/173046 [======================>.......] - ETA: 0s - loss: 0.0781 - acc: 0.9708 - mean_squared_error: 0.0248
143750/173046 [=======================>......] - ETA: 0s - loss: 0.0786 - acc: 0.9706 - mean_squared_error: 0.0249
149500/173046 [========================>.....] - ETA: 0s - loss: 0.0786 - acc: 0.9706 - mean_squared_error: 0.0249
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0785 - acc: 0.9707 - mean_squared_error: 0.0249
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0785 - acc: 0.9708 - mean_squared_error: 0.0248
166750/173046 [===========================>..] - ETA: 0s - loss: 0.0780 - acc: 0.9708 - mean_squared_error: 0.0248
172500/173046 [============================>.] - ETA: 0s - loss: 0.0788 - acc: 0.9708 - mean_squared_error: 0.0248
173046/173046 [==============================] - 2s 11us/step - loss: 0.0788 - acc: 0.9708 - mean_squared_error: 0.0249 - val_loss: 5.1860e-04 - val_acc: 0.9708 - val_mean_squared_error: 0.0255

Epoch 00036: val_loss did not improve
Epoch 37/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0315 - acc: 0.9600 - mean_squared_error: 0.0359
  6000/173046 [>.............................] - ETA: 1s - loss: 0.1007 - acc: 0.9635 - mean_squared_error: 0.0308
 11750/173046 [=>............................] - ETA: 1s - loss: 0.0888 - acc: 0.9660 - mean_squared_error: 0.0288
 17750/173046 [==>...........................] - ETA: 1s - loss: 0.0809 - acc: 0.9680 - mean_squared_error: 0.0272
 24000/173046 [===>..........................] - ETA: 1s - loss: 0.0809 - acc: 0.9680 - mean_squared_error: 0.0272
 30250/173046 [====>.........................] - ETA: 1s - loss: 0.0793 - acc: 0.9682 - mean_squared_error: 0.0270
 36500/173046 [=====>........................] - ETA: 1s - loss: 0.0792 - acc: 0.9682 - mean_squared_error: 0.0271
 42750/173046 [======>.......................] - ETA: 1s - loss: 0.0820 - acc: 0.9683 - mean_squared_error: 0.0272
 49000/173046 [=======>......................] - ETA: 1s - loss: 0.0829 - acc: 0.9690 - mean_squared_error: 0.0267
 55250/173046 [========>.....................] - ETA: 0s - loss: 0.0798 - acc: 0.9695 - mean_squared_error: 0.0262
 61500/173046 [=========>....................] - ETA: 0s - loss: 0.0805 - acc: 0.9696 - mean_squared_error: 0.0261
 67750/173046 [==========>...................] - ETA: 0s - loss: 0.0803 - acc: 0.9701 - mean_squared_error: 0.0258
 74000/173046 [===========>..................] - ETA: 0s - loss: 0.0810 - acc: 0.9701 - mean_squared_error: 0.0258
 80250/173046 [============>.................] - ETA: 0s - loss: 0.0813 - acc: 0.9701 - mean_squared_error: 0.0258
 86500/173046 [=============>................] - ETA: 0s - loss: 0.0810 - acc: 0.9701 - mean_squared_error: 0.0257
 92750/173046 [===============>..............] - ETA: 0s - loss: 0.0808 - acc: 0.9700 - mean_squared_error: 0.0258
 99000/173046 [================>.............] - ETA: 0s - loss: 0.0809 - acc: 0.9703 - mean_squared_error: 0.0255
105250/173046 [=================>............] - ETA: 0s - loss: 0.0802 - acc: 0.9705 - mean_squared_error: 0.0253
111500/173046 [==================>...........] - ETA: 0s - loss: 0.0807 - acc: 0.9705 - mean_squared_error: 0.0253
117750/173046 [===================>..........] - ETA: 0s - loss: 0.0799 - acc: 0.9705 - mean_squared_error: 0.0252
124000/173046 [====================>.........] - ETA: 0s - loss: 0.0793 - acc: 0.9706 - mean_squared_error: 0.0252
130250/173046 [=====================>........] - ETA: 0s - loss: 0.0788 - acc: 0.9707 - mean_squared_error: 0.0251
136500/173046 [======================>.......] - ETA: 0s - loss: 0.0786 - acc: 0.9706 - mean_squared_error: 0.0251
142750/173046 [=======================>......] - ETA: 0s - loss: 0.0791 - acc: 0.9707 - mean_squared_error: 0.0251
149000/173046 [========================>.....] - ETA: 0s - loss: 0.0805 - acc: 0.9706 - mean_squared_error: 0.0251
155250/173046 [=========================>....] - ETA: 0s - loss: 0.0811 - acc: 0.9705 - mean_squared_error: 0.0253
161500/173046 [==========================>...] - ETA: 0s - loss: 0.0807 - acc: 0.9706 - mean_squared_error: 0.0252
167750/173046 [============================>.] - ETA: 0s - loss: 0.0798 - acc: 0.9706 - mean_squared_error: 0.0251
173046/173046 [==============================] - 2s 10us/step - loss: 0.0793 - acc: 0.9706 - mean_squared_error: 0.0251 - val_loss: 5.3273e-04 - val_acc: 0.9707 - val_mean_squared_error: 0.0257

Epoch 00037: val_loss did not improve
Epoch 38/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1623 - acc: 0.9880 - mean_squared_error: 0.0093
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0712 - acc: 0.9737 - mean_squared_error: 0.0227
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0657 - acc: 0.9736 - mean_squared_error: 0.0228
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0676 - acc: 0.9729 - mean_squared_error: 0.0233
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0682 - acc: 0.9731 - mean_squared_error: 0.0232
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0700 - acc: 0.9724 - mean_squared_error: 0.0237
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0736 - acc: 0.9723 - mean_squared_error: 0.0239
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0743 - acc: 0.9723 - mean_squared_error: 0.0239
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0750 - acc: 0.9721 - mean_squared_error: 0.0241
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0768 - acc: 0.9720 - mean_squared_error: 0.0240
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0776 - acc: 0.9717 - mean_squared_error: 0.0242
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0775 - acc: 0.9719 - mean_squared_error: 0.0240
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0783 - acc: 0.9719 - mean_squared_error: 0.0240
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0777 - acc: 0.9720 - mean_squared_error: 0.0239
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0762 - acc: 0.9720 - mean_squared_error: 0.0239
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0771 - acc: 0.9719 - mean_squared_error: 0.0240
100250/173046 [================>.............] - ETA: 0s - loss: 0.0766 - acc: 0.9721 - mean_squared_error: 0.0238
106500/173046 [=================>............] - ETA: 0s - loss: 0.0757 - acc: 0.9721 - mean_squared_error: 0.0238
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0755 - acc: 0.9721 - mean_squared_error: 0.0238
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0747 - acc: 0.9720 - mean_squared_error: 0.0239
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0754 - acc: 0.9717 - mean_squared_error: 0.0241
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0765 - acc: 0.9714 - mean_squared_error: 0.0245
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0772 - acc: 0.9713 - mean_squared_error: 0.0246
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0778 - acc: 0.9713 - mean_squared_error: 0.0246
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0784 - acc: 0.9713 - mean_squared_error: 0.0245
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0792 - acc: 0.9712 - mean_squared_error: 0.0246
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0790 - acc: 0.9711 - mean_squared_error: 0.0247
169000/173046 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9711 - mean_squared_error: 0.0247
173046/173046 [==============================] - 2s 10us/step - loss: 0.0780 - acc: 0.9711 - mean_squared_error: 0.0247 - val_loss: 7.1460e-04 - val_acc: 0.9669 - val_mean_squared_error: 0.0296

Epoch 00038: val_loss did not improve
Epoch 39/50

   250/173046 [..............................] - ETA: 4s - loss: 0.2087 - acc: 0.9640 - mean_squared_error: 0.0308
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0744 - acc: 0.9718 - mean_squared_error: 0.0243
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0827 - acc: 0.9709 - mean_squared_error: 0.0248
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0845 - acc: 0.9701 - mean_squared_error: 0.0254
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0824 - acc: 0.9703 - mean_squared_error: 0.0255
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0808 - acc: 0.9700 - mean_squared_error: 0.0257
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0782 - acc: 0.9712 - mean_squared_error: 0.0248
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0815 - acc: 0.9711 - mean_squared_error: 0.0249
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0817 - acc: 0.9710 - mean_squared_error: 0.0250
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0805 - acc: 0.9712 - mean_squared_error: 0.0248
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0800 - acc: 0.9714 - mean_squared_error: 0.0246
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0808 - acc: 0.9712 - mean_squared_error: 0.0248
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0795 - acc: 0.9714 - mean_squared_error: 0.0246
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0780 - acc: 0.9714 - mean_squared_error: 0.0246
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0772 - acc: 0.9713 - mean_squared_error: 0.0247
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0781 - acc: 0.9712 - mean_squared_error: 0.0248
100250/173046 [================>.............] - ETA: 0s - loss: 0.0783 - acc: 0.9712 - mean_squared_error: 0.0247
106500/173046 [=================>............] - ETA: 0s - loss: 0.0775 - acc: 0.9711 - mean_squared_error: 0.0249
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0767 - acc: 0.9712 - mean_squared_error: 0.0248
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0773 - acc: 0.9711 - mean_squared_error: 0.0248
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0775 - acc: 0.9711 - mean_squared_error: 0.0249
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0782 - acc: 0.9709 - mean_squared_error: 0.0250
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0784 - acc: 0.9708 - mean_squared_error: 0.0250
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0779 - acc: 0.9709 - mean_squared_error: 0.0249
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0780 - acc: 0.9709 - mean_squared_error: 0.0249
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0779 - acc: 0.9711 - mean_squared_error: 0.0248
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0780 - acc: 0.9712 - mean_squared_error: 0.0247
169000/173046 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9712 - mean_squared_error: 0.0247
173046/173046 [==============================] - 2s 10us/step - loss: 0.0778 - acc: 0.9711 - mean_squared_error: 0.0247 - val_loss: 4.5309e-04 - val_acc: 0.9706 - val_mean_squared_error: 0.0251

Epoch 00039: val_loss did not improve
Epoch 40/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0269 - acc: 0.9760 - mean_squared_error: 0.0215
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0912 - acc: 0.9735 - mean_squared_error: 0.0224
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0859 - acc: 0.9711 - mean_squared_error: 0.0245
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0805 - acc: 0.9711 - mean_squared_error: 0.0244
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0827 - acc: 0.9704 - mean_squared_error: 0.0251
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0816 - acc: 0.9705 - mean_squared_error: 0.0252
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0808 - acc: 0.9697 - mean_squared_error: 0.0259
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0796 - acc: 0.9699 - mean_squared_error: 0.0256
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0780 - acc: 0.9702 - mean_squared_error: 0.0253
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0753 - acc: 0.9707 - mean_squared_error: 0.0250
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0745 - acc: 0.9707 - mean_squared_error: 0.0249
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0734 - acc: 0.9707 - mean_squared_error: 0.0249
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0724 - acc: 0.9707 - mean_squared_error: 0.0250
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0731 - acc: 0.9708 - mean_squared_error: 0.0248
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0742 - acc: 0.9707 - mean_squared_error: 0.0249
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0749 - acc: 0.9704 - mean_squared_error: 0.0251
100250/173046 [================>.............] - ETA: 0s - loss: 0.0756 - acc: 0.9704 - mean_squared_error: 0.0252
106500/173046 [=================>............] - ETA: 0s - loss: 0.0768 - acc: 0.9702 - mean_squared_error: 0.0253
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0768 - acc: 0.9705 - mean_squared_error: 0.0251
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0779 - acc: 0.9705 - mean_squared_error: 0.0251
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0778 - acc: 0.9708 - mean_squared_error: 0.0249
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0782 - acc: 0.9707 - mean_squared_error: 0.0249
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0773 - acc: 0.9709 - mean_squared_error: 0.0247
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0774 - acc: 0.9708 - mean_squared_error: 0.0248
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0769 - acc: 0.9707 - mean_squared_error: 0.0248
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0768 - acc: 0.9707 - mean_squared_error: 0.0249
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0770 - acc: 0.9706 - mean_squared_error: 0.0249
169000/173046 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9707 - mean_squared_error: 0.0248
173046/173046 [==============================] - 2s 10us/step - loss: 0.0782 - acc: 0.9707 - mean_squared_error: 0.0248 - val_loss: 3.7603e-04 - val_acc: 0.9708 - val_mean_squared_error: 0.0244

Epoch 00040: val_loss did not improve
Epoch 41/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0474 - acc: 0.9600 - mean_squared_error: 0.0320
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0739 - acc: 0.9723 - mean_squared_error: 0.0244
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0796 - acc: 0.9726 - mean_squared_error: 0.0239
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0784 - acc: 0.9725 - mean_squared_error: 0.0236
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0800 - acc: 0.9724 - mean_squared_error: 0.0237
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0760 - acc: 0.9725 - mean_squared_error: 0.0237
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0765 - acc: 0.9722 - mean_squared_error: 0.0239
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0754 - acc: 0.9723 - mean_squared_error: 0.0237
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0749 - acc: 0.9721 - mean_squared_error: 0.0240
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0753 - acc: 0.9720 - mean_squared_error: 0.0241
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0780 - acc: 0.9716 - mean_squared_error: 0.0243
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0782 - acc: 0.9717 - mean_squared_error: 0.0243
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0783 - acc: 0.9716 - mean_squared_error: 0.0244
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0795 - acc: 0.9715 - mean_squared_error: 0.0243
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0819 - acc: 0.9711 - mean_squared_error: 0.0247
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0803 - acc: 0.9710 - mean_squared_error: 0.0248
100250/173046 [================>.............] - ETA: 0s - loss: 0.0812 - acc: 0.9709 - mean_squared_error: 0.0248
106500/173046 [=================>............] - ETA: 0s - loss: 0.0800 - acc: 0.9710 - mean_squared_error: 0.0248
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0805 - acc: 0.9710 - mean_squared_error: 0.0247
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0801 - acc: 0.9710 - mean_squared_error: 0.0248
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0794 - acc: 0.9710 - mean_squared_error: 0.0248
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0791 - acc: 0.9711 - mean_squared_error: 0.0247
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0788 - acc: 0.9711 - mean_squared_error: 0.0247
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0775 - acc: 0.9712 - mean_squared_error: 0.0246
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0766 - acc: 0.9714 - mean_squared_error: 0.0245
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0766 - acc: 0.9714 - mean_squared_error: 0.0245
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0769 - acc: 0.9713 - mean_squared_error: 0.0245
169000/173046 [============================>.] - ETA: 0s - loss: 0.0772 - acc: 0.9714 - mean_squared_error: 0.0245
173046/173046 [==============================] - 2s 10us/step - loss: 0.0770 - acc: 0.9714 - mean_squared_error: 0.0245 - val_loss: 5.7699e-04 - val_acc: 0.9693 - val_mean_squared_error: 0.0271

Epoch 00041: val_loss did not improve
Epoch 42/50

   250/173046 [..............................] - ETA: 4s - loss: 0.1168 - acc: 0.9760 - mean_squared_error: 0.0225
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0784 - acc: 0.9717 - mean_squared_error: 0.0244
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0757 - acc: 0.9707 - mean_squared_error: 0.0255
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0823 - acc: 0.9698 - mean_squared_error: 0.0255
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0803 - acc: 0.9710 - mean_squared_error: 0.0245
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0839 - acc: 0.9720 - mean_squared_error: 0.0238
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0844 - acc: 0.9715 - mean_squared_error: 0.0243
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0820 - acc: 0.9719 - mean_squared_error: 0.0239
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0810 - acc: 0.9718 - mean_squared_error: 0.0240
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0804 - acc: 0.9715 - mean_squared_error: 0.0243
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0794 - acc: 0.9716 - mean_squared_error: 0.0242
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0794 - acc: 0.9712 - mean_squared_error: 0.0246
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0801 - acc: 0.9711 - mean_squared_error: 0.0247
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0797 - acc: 0.9711 - mean_squared_error: 0.0247
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0788 - acc: 0.9714 - mean_squared_error: 0.0244
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0792 - acc: 0.9712 - mean_squared_error: 0.0246
100250/173046 [================>.............] - ETA: 0s - loss: 0.0787 - acc: 0.9709 - mean_squared_error: 0.0248
106500/173046 [=================>............] - ETA: 0s - loss: 0.0792 - acc: 0.9708 - mean_squared_error: 0.0248
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0787 - acc: 0.9707 - mean_squared_error: 0.0249
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0779 - acc: 0.9709 - mean_squared_error: 0.0248
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0773 - acc: 0.9709 - mean_squared_error: 0.0247
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0785 - acc: 0.9708 - mean_squared_error: 0.0249
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0782 - acc: 0.9707 - mean_squared_error: 0.0249
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0794 - acc: 0.9706 - mean_squared_error: 0.0250
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0790 - acc: 0.9707 - mean_squared_error: 0.0249
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0790 - acc: 0.9708 - mean_squared_error: 0.0249
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0786 - acc: 0.9709 - mean_squared_error: 0.0248
169000/173046 [============================>.] - ETA: 0s - loss: 0.0777 - acc: 0.9708 - mean_squared_error: 0.0248
173046/173046 [==============================] - 2s 10us/step - loss: 0.0782 - acc: 0.9707 - mean_squared_error: 0.0249 - val_loss: 4.6232e-04 - val_acc: 0.9723 - val_mean_squared_error: 0.0239

Epoch 00042: val_loss did not improve
Epoch 43/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0305 - acc: 0.9800 - mean_squared_error: 0.0154
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0760 - acc: 0.9726 - mean_squared_error: 0.0225
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0808 - acc: 0.9700 - mean_squared_error: 0.0246
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0859 - acc: 0.9698 - mean_squared_error: 0.0251
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0834 - acc: 0.9705 - mean_squared_error: 0.0246
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0830 - acc: 0.9700 - mean_squared_error: 0.0253
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0804 - acc: 0.9701 - mean_squared_error: 0.0251
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0773 - acc: 0.9701 - mean_squared_error: 0.0251
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0773 - acc: 0.9703 - mean_squared_error: 0.0249
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0777 - acc: 0.9702 - mean_squared_error: 0.0250
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0773 - acc: 0.9704 - mean_squared_error: 0.0250
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0783 - acc: 0.9703 - mean_squared_error: 0.0250
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0775 - acc: 0.9706 - mean_squared_error: 0.0248
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0773 - acc: 0.9708 - mean_squared_error: 0.0246
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0773 - acc: 0.9709 - mean_squared_error: 0.0246
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0776 - acc: 0.9707 - mean_squared_error: 0.0248
100250/173046 [================>.............] - ETA: 0s - loss: 0.0780 - acc: 0.9709 - mean_squared_error: 0.0246
106500/173046 [=================>............] - ETA: 0s - loss: 0.0770 - acc: 0.9708 - mean_squared_error: 0.0247
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0760 - acc: 0.9711 - mean_squared_error: 0.0246
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0756 - acc: 0.9712 - mean_squared_error: 0.0244
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0758 - acc: 0.9712 - mean_squared_error: 0.0245
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0763 - acc: 0.9714 - mean_squared_error: 0.0244
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0757 - acc: 0.9714 - mean_squared_error: 0.0244
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0760 - acc: 0.9713 - mean_squared_error: 0.0245
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0757 - acc: 0.9713 - mean_squared_error: 0.0244
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0767 - acc: 0.9711 - mean_squared_error: 0.0246
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0767 - acc: 0.9711 - mean_squared_error: 0.0247
169000/173046 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9710 - mean_squared_error: 0.0247
173046/173046 [==============================] - 2s 10us/step - loss: 0.0774 - acc: 0.9710 - mean_squared_error: 0.0247 - val_loss: 4.9989e-04 - val_acc: 0.9709 - val_mean_squared_error: 0.0254

Epoch 00043: val_loss did not improve
Epoch 44/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0833 - acc: 0.9720 - mean_squared_error: 0.0243
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0737 - acc: 0.9731 - mean_squared_error: 0.0239
 12500/173046 [=>............................] - ETA: 1s - loss: 0.0812 - acc: 0.9715 - mean_squared_error: 0.0249
 18500/173046 [==>...........................] - ETA: 1s - loss: 0.0885 - acc: 0.9704 - mean_squared_error: 0.0258
 24500/173046 [===>..........................] - ETA: 1s - loss: 0.0896 - acc: 0.9699 - mean_squared_error: 0.0266
 30500/173046 [====>.........................] - ETA: 1s - loss: 0.0869 - acc: 0.9706 - mean_squared_error: 0.0259
 36500/173046 [=====>........................] - ETA: 1s - loss: 0.0827 - acc: 0.9708 - mean_squared_error: 0.0254
 42500/173046 [======>.......................] - ETA: 1s - loss: 0.0803 - acc: 0.9713 - mean_squared_error: 0.0249
 48750/173046 [=======>......................] - ETA: 1s - loss: 0.0798 - acc: 0.9713 - mean_squared_error: 0.0249
 55000/173046 [========>.....................] - ETA: 0s - loss: 0.0800 - acc: 0.9714 - mean_squared_error: 0.0249
 61000/173046 [=========>....................] - ETA: 0s - loss: 0.0778 - acc: 0.9716 - mean_squared_error: 0.0245
 67250/173046 [==========>...................] - ETA: 0s - loss: 0.0771 - acc: 0.9714 - mean_squared_error: 0.0247
 73500/173046 [===========>..................] - ETA: 0s - loss: 0.0765 - acc: 0.9714 - mean_squared_error: 0.0246
 79750/173046 [============>.................] - ETA: 0s - loss: 0.0768 - acc: 0.9713 - mean_squared_error: 0.0246
 86000/173046 [=============>................] - ETA: 0s - loss: 0.0773 - acc: 0.9712 - mean_squared_error: 0.0247
 92250/173046 [==============>...............] - ETA: 0s - loss: 0.0775 - acc: 0.9712 - mean_squared_error: 0.0248
 98500/173046 [================>.............] - ETA: 0s - loss: 0.0782 - acc: 0.9712 - mean_squared_error: 0.0248
104750/173046 [=================>............] - ETA: 0s - loss: 0.0778 - acc: 0.9710 - mean_squared_error: 0.0250
111000/173046 [==================>...........] - ETA: 0s - loss: 0.0780 - acc: 0.9711 - mean_squared_error: 0.0248
117250/173046 [===================>..........] - ETA: 0s - loss: 0.0777 - acc: 0.9710 - mean_squared_error: 0.0249
123500/173046 [====================>.........] - ETA: 0s - loss: 0.0786 - acc: 0.9711 - mean_squared_error: 0.0249
129750/173046 [=====================>........] - ETA: 0s - loss: 0.0787 - acc: 0.9711 - mean_squared_error: 0.0248
136000/173046 [======================>.......] - ETA: 0s - loss: 0.0790 - acc: 0.9711 - mean_squared_error: 0.0248
142250/173046 [=======================>......] - ETA: 0s - loss: 0.0780 - acc: 0.9710 - mean_squared_error: 0.0250
148500/173046 [========================>.....] - ETA: 0s - loss: 0.0781 - acc: 0.9710 - mean_squared_error: 0.0250
154750/173046 [=========================>....] - ETA: 0s - loss: 0.0782 - acc: 0.9710 - mean_squared_error: 0.0249
161000/173046 [==========================>...] - ETA: 0s - loss: 0.0791 - acc: 0.9711 - mean_squared_error: 0.0249
167250/173046 [===========================>..] - ETA: 0s - loss: 0.0790 - acc: 0.9711 - mean_squared_error: 0.0249
173046/173046 [==============================] - 2s 10us/step - loss: 0.0785 - acc: 0.9711 - mean_squared_error: 0.0249 - val_loss: 4.4699e-04 - val_acc: 0.9712 - val_mean_squared_error: 0.0246

Epoch 00044: val_loss did not improve
Epoch 45/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0329 - acc: 0.9640 - mean_squared_error: 0.0304
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0706 - acc: 0.9740 - mean_squared_error: 0.0218
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0654 - acc: 0.9746 - mean_squared_error: 0.0214
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0656 - acc: 0.9747 - mean_squared_error: 0.0211
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0649 - acc: 0.9736 - mean_squared_error: 0.0221
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0672 - acc: 0.9730 - mean_squared_error: 0.0227
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0674 - acc: 0.9727 - mean_squared_error: 0.0231
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0670 - acc: 0.9730 - mean_squared_error: 0.0229
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0694 - acc: 0.9725 - mean_squared_error: 0.0234
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0705 - acc: 0.9723 - mean_squared_error: 0.0236
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0710 - acc: 0.9725 - mean_squared_error: 0.0233
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0707 - acc: 0.9722 - mean_squared_error: 0.0236
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0692 - acc: 0.9720 - mean_squared_error: 0.0238
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0719 - acc: 0.9716 - mean_squared_error: 0.0240
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0721 - acc: 0.9715 - mean_squared_error: 0.0241
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0735 - acc: 0.9714 - mean_squared_error: 0.0242
100250/173046 [================>.............] - ETA: 0s - loss: 0.0747 - acc: 0.9714 - mean_squared_error: 0.0242
106500/173046 [=================>............] - ETA: 0s - loss: 0.0752 - acc: 0.9713 - mean_squared_error: 0.0243
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0761 - acc: 0.9711 - mean_squared_error: 0.0245
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0757 - acc: 0.9713 - mean_squared_error: 0.0243
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0759 - acc: 0.9714 - mean_squared_error: 0.0243
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0761 - acc: 0.9713 - mean_squared_error: 0.0243
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0766 - acc: 0.9712 - mean_squared_error: 0.0245
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0774 - acc: 0.9711 - mean_squared_error: 0.0246
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0775 - acc: 0.9711 - mean_squared_error: 0.0246
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0770 - acc: 0.9711 - mean_squared_error: 0.0246
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0776 - acc: 0.9710 - mean_squared_error: 0.0246
169000/173046 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9711 - mean_squared_error: 0.0246
173046/173046 [==============================] - 2s 10us/step - loss: 0.0773 - acc: 0.9712 - mean_squared_error: 0.0245 - val_loss: 4.0226e-04 - val_acc: 0.9714 - val_mean_squared_error: 0.0241

Epoch 00045: val_loss did not improve
Epoch 46/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0446 - acc: 0.9680 - mean_squared_error: 0.0266
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0818 - acc: 0.9692 - mean_squared_error: 0.0265
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0720 - acc: 0.9725 - mean_squared_error: 0.0237
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0767 - acc: 0.9711 - mean_squared_error: 0.0246
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0736 - acc: 0.9719 - mean_squared_error: 0.0240
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0769 - acc: 0.9716 - mean_squared_error: 0.0242
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0766 - acc: 0.9710 - mean_squared_error: 0.0246
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0740 - acc: 0.9712 - mean_squared_error: 0.0245
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0743 - acc: 0.9708 - mean_squared_error: 0.0249
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0769 - acc: 0.9709 - mean_squared_error: 0.0248
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0782 - acc: 0.9708 - mean_squared_error: 0.0248
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0794 - acc: 0.9705 - mean_squared_error: 0.0251
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0786 - acc: 0.9707 - mean_squared_error: 0.0250
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0795 - acc: 0.9705 - mean_squared_error: 0.0252
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0788 - acc: 0.9707 - mean_squared_error: 0.0249
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0789 - acc: 0.9709 - mean_squared_error: 0.0248
100250/173046 [================>.............] - ETA: 0s - loss: 0.0794 - acc: 0.9704 - mean_squared_error: 0.0252
106500/173046 [=================>............] - ETA: 0s - loss: 0.0797 - acc: 0.9704 - mean_squared_error: 0.0252
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0787 - acc: 0.9704 - mean_squared_error: 0.0251
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0780 - acc: 0.9706 - mean_squared_error: 0.0250
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0774 - acc: 0.9706 - mean_squared_error: 0.0250
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0766 - acc: 0.9707 - mean_squared_error: 0.0249
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0761 - acc: 0.9708 - mean_squared_error: 0.0249
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0763 - acc: 0.9708 - mean_squared_error: 0.0248
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0768 - acc: 0.9709 - mean_squared_error: 0.0247
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0767 - acc: 0.9708 - mean_squared_error: 0.0248
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0771 - acc: 0.9709 - mean_squared_error: 0.0247
169000/173046 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9709 - mean_squared_error: 0.0246
173046/173046 [==============================] - 2s 10us/step - loss: 0.0767 - acc: 0.9710 - mean_squared_error: 0.0246 - val_loss: 3.7529e-04 - val_acc: 0.9709 - val_mean_squared_error: 0.0244

Epoch 00046: val_loss did not improve
Epoch 47/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0936 - acc: 0.9760 - mean_squared_error: 0.0237
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0760 - acc: 0.9729 - mean_squared_error: 0.0228
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0806 - acc: 0.9708 - mean_squared_error: 0.0247
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0833 - acc: 0.9723 - mean_squared_error: 0.0238
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0820 - acc: 0.9727 - mean_squared_error: 0.0235
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0792 - acc: 0.9719 - mean_squared_error: 0.0240
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0773 - acc: 0.9714 - mean_squared_error: 0.0243
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0766 - acc: 0.9718 - mean_squared_error: 0.0240
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0769 - acc: 0.9710 - mean_squared_error: 0.0247
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0768 - acc: 0.9712 - mean_squared_error: 0.0245
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0763 - acc: 0.9713 - mean_squared_error: 0.0246
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0772 - acc: 0.9713 - mean_squared_error: 0.0245
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0787 - acc: 0.9712 - mean_squared_error: 0.0246
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0787 - acc: 0.9712 - mean_squared_error: 0.0247
 87000/173046 [==============>...............] - ETA: 0s - loss: 0.0772 - acc: 0.9714 - mean_squared_error: 0.0245
 92750/173046 [===============>..............] - ETA: 0s - loss: 0.0771 - acc: 0.9714 - mean_squared_error: 0.0245
 98500/173046 [================>.............] - ETA: 0s - loss: 0.0765 - acc: 0.9714 - mean_squared_error: 0.0245
104250/173046 [=================>............] - ETA: 0s - loss: 0.0768 - acc: 0.9713 - mean_squared_error: 0.0245
110000/173046 [==================>...........] - ETA: 0s - loss: 0.0772 - acc: 0.9712 - mean_squared_error: 0.0246
115750/173046 [===================>..........] - ETA: 0s - loss: 0.0763 - acc: 0.9714 - mean_squared_error: 0.0244
121500/173046 [====================>.........] - ETA: 0s - loss: 0.0767 - acc: 0.9713 - mean_squared_error: 0.0245
127250/173046 [=====================>........] - ETA: 0s - loss: 0.0780 - acc: 0.9711 - mean_squared_error: 0.0246
133000/173046 [======================>.......] - ETA: 0s - loss: 0.0785 - acc: 0.9709 - mean_squared_error: 0.0247
138750/173046 [=======================>......] - ETA: 0s - loss: 0.0787 - acc: 0.9709 - mean_squared_error: 0.0248
144500/173046 [========================>.....] - ETA: 0s - loss: 0.0783 - acc: 0.9710 - mean_squared_error: 0.0248
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0788 - acc: 0.9710 - mean_squared_error: 0.0247
156000/173046 [==========================>...] - ETA: 0s - loss: 0.0787 - acc: 0.9709 - mean_squared_error: 0.0248
161750/173046 [===========================>..] - ETA: 0s - loss: 0.0778 - acc: 0.9710 - mean_squared_error: 0.0247
167500/173046 [============================>.] - ETA: 0s - loss: 0.0775 - acc: 0.9710 - mean_squared_error: 0.0247
173046/173046 [==============================] - 2s 10us/step - loss: 0.0776 - acc: 0.9710 - mean_squared_error: 0.0247 - val_loss: 4.0040e-04 - val_acc: 0.9696 - val_mean_squared_error: 0.0255

Epoch 00047: val_loss did not improve
Epoch 48/50

   250/173046 [..............................] - ETA: 5s - loss: 0.0781 - acc: 0.9600 - mean_squared_error: 0.0321
  6000/173046 [>.............................] - ETA: 1s - loss: 0.0792 - acc: 0.9692 - mean_squared_error: 0.0264
 11750/173046 [=>............................] - ETA: 1s - loss: 0.0750 - acc: 0.9710 - mean_squared_error: 0.0251
 17500/173046 [==>...........................] - ETA: 1s - loss: 0.0796 - acc: 0.9712 - mean_squared_error: 0.0245
 23250/173046 [===>..........................] - ETA: 1s - loss: 0.0787 - acc: 0.9713 - mean_squared_error: 0.0243
 29000/173046 [====>.........................] - ETA: 1s - loss: 0.0848 - acc: 0.9707 - mean_squared_error: 0.0248
 34750/173046 [=====>........................] - ETA: 1s - loss: 0.0836 - acc: 0.9704 - mean_squared_error: 0.0250
 40500/173046 [======>.......................] - ETA: 1s - loss: 0.0829 - acc: 0.9700 - mean_squared_error: 0.0254
 46250/173046 [=======>......................] - ETA: 1s - loss: 0.0792 - acc: 0.9706 - mean_squared_error: 0.0249
 52000/173046 [========>.....................] - ETA: 1s - loss: 0.0775 - acc: 0.9709 - mean_squared_error: 0.0247
 57750/173046 [=========>....................] - ETA: 1s - loss: 0.0752 - acc: 0.9710 - mean_squared_error: 0.0247
 63500/173046 [==========>...................] - ETA: 0s - loss: 0.0755 - acc: 0.9708 - mean_squared_error: 0.0249
 69250/173046 [===========>..................] - ETA: 0s - loss: 0.0770 - acc: 0.9711 - mean_squared_error: 0.0247
 75000/173046 [============>.................] - ETA: 0s - loss: 0.0770 - acc: 0.9712 - mean_squared_error: 0.0246
 80500/173046 [============>.................] - ETA: 0s - loss: 0.0772 - acc: 0.9714 - mean_squared_error: 0.0245
 86000/173046 [=============>................] - ETA: 0s - loss: 0.0772 - acc: 0.9714 - mean_squared_error: 0.0244
 91500/173046 [==============>...............] - ETA: 0s - loss: 0.0765 - acc: 0.9710 - mean_squared_error: 0.0248
 97000/173046 [===============>..............] - ETA: 0s - loss: 0.0773 - acc: 0.9713 - mean_squared_error: 0.0246
103000/173046 [================>.............] - ETA: 0s - loss: 0.0769 - acc: 0.9712 - mean_squared_error: 0.0246
109250/173046 [=================>............] - ETA: 0s - loss: 0.0762 - acc: 0.9711 - mean_squared_error: 0.0247
115250/173046 [==================>...........] - ETA: 0s - loss: 0.0761 - acc: 0.9711 - mean_squared_error: 0.0247
121250/173046 [====================>.........] - ETA: 0s - loss: 0.0770 - acc: 0.9709 - mean_squared_error: 0.0248
127000/173046 [=====================>........] - ETA: 0s - loss: 0.0769 - acc: 0.9709 - mean_squared_error: 0.0248
133000/173046 [======================>.......] - ETA: 0s - loss: 0.0786 - acc: 0.9707 - mean_squared_error: 0.0251
139250/173046 [=======================>......] - ETA: 0s - loss: 0.0779 - acc: 0.9706 - mean_squared_error: 0.0251
145500/173046 [========================>.....] - ETA: 0s - loss: 0.0779 - acc: 0.9707 - mean_squared_error: 0.0251
151750/173046 [=========================>....] - ETA: 0s - loss: 0.0769 - acc: 0.9707 - mean_squared_error: 0.0250
158000/173046 [==========================>...] - ETA: 0s - loss: 0.0771 - acc: 0.9709 - mean_squared_error: 0.0249
164250/173046 [===========================>..] - ETA: 0s - loss: 0.0781 - acc: 0.9708 - mean_squared_error: 0.0250
170500/173046 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9707 - mean_squared_error: 0.0250
173046/173046 [==============================] - 2s 10us/step - loss: 0.0789 - acc: 0.9707 - mean_squared_error: 0.0251 - val_loss: 4.1237e-04 - val_acc: 0.9663 - val_mean_squared_error: 0.0285

Epoch 00048: val_loss did not improve
Epoch 49/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0528 - acc: 0.9760 - mean_squared_error: 0.0216
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0776 - acc: 0.9720 - mean_squared_error: 0.0235
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0766 - acc: 0.9726 - mean_squared_error: 0.0231
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0741 - acc: 0.9729 - mean_squared_error: 0.0230
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0759 - acc: 0.9720 - mean_squared_error: 0.0238
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0790 - acc: 0.9724 - mean_squared_error: 0.0236
 35000/173046 [=====>........................] - ETA: 1s - loss: 0.0797 - acc: 0.9724 - mean_squared_error: 0.0237
 41250/173046 [======>.......................] - ETA: 1s - loss: 0.0798 - acc: 0.9723 - mean_squared_error: 0.0237
 47500/173046 [=======>......................] - ETA: 1s - loss: 0.0800 - acc: 0.9720 - mean_squared_error: 0.0239
 53750/173046 [========>.....................] - ETA: 1s - loss: 0.0802 - acc: 0.9719 - mean_squared_error: 0.0240
 60000/173046 [=========>....................] - ETA: 0s - loss: 0.0824 - acc: 0.9713 - mean_squared_error: 0.0245
 66250/173046 [==========>...................] - ETA: 0s - loss: 0.0794 - acc: 0.9714 - mean_squared_error: 0.0244
 72500/173046 [===========>..................] - ETA: 0s - loss: 0.0784 - acc: 0.9717 - mean_squared_error: 0.0242
 78750/173046 [============>.................] - ETA: 0s - loss: 0.0792 - acc: 0.9716 - mean_squared_error: 0.0243
 85000/173046 [=============>................] - ETA: 0s - loss: 0.0795 - acc: 0.9712 - mean_squared_error: 0.0245
 91250/173046 [==============>...............] - ETA: 0s - loss: 0.0792 - acc: 0.9712 - mean_squared_error: 0.0246
 97500/173046 [===============>..............] - ETA: 0s - loss: 0.0789 - acc: 0.9712 - mean_squared_error: 0.0246
103750/173046 [================>.............] - ETA: 0s - loss: 0.0786 - acc: 0.9712 - mean_squared_error: 0.0245
110000/173046 [==================>...........] - ETA: 0s - loss: 0.0787 - acc: 0.9713 - mean_squared_error: 0.0244
116250/173046 [===================>..........] - ETA: 0s - loss: 0.0787 - acc: 0.9714 - mean_squared_error: 0.0244
122500/173046 [====================>.........] - ETA: 0s - loss: 0.0791 - acc: 0.9711 - mean_squared_error: 0.0246
128750/173046 [=====================>........] - ETA: 0s - loss: 0.0789 - acc: 0.9711 - mean_squared_error: 0.0247
135000/173046 [======================>.......] - ETA: 0s - loss: 0.0783 - acc: 0.9712 - mean_squared_error: 0.0246
141250/173046 [=======================>......] - ETA: 0s - loss: 0.0781 - acc: 0.9712 - mean_squared_error: 0.0246
147500/173046 [========================>.....] - ETA: 0s - loss: 0.0788 - acc: 0.9712 - mean_squared_error: 0.0246
153750/173046 [=========================>....] - ETA: 0s - loss: 0.0793 - acc: 0.9712 - mean_squared_error: 0.0246
160000/173046 [==========================>...] - ETA: 0s - loss: 0.0783 - acc: 0.9713 - mean_squared_error: 0.0245
166250/173046 [===========================>..] - ETA: 0s - loss: 0.0773 - acc: 0.9713 - mean_squared_error: 0.0245
172500/173046 [============================>.] - ETA: 0s - loss: 0.0774 - acc: 0.9712 - mean_squared_error: 0.0246
173046/173046 [==============================] - 2s 10us/step - loss: 0.0774 - acc: 0.9712 - mean_squared_error: 0.0246 - val_loss: 4.1786e-04 - val_acc: 0.9707 - val_mean_squared_error: 0.0249

Epoch 00049: val_loss did not improve
Epoch 50/50

   250/173046 [..............................] - ETA: 4s - loss: 0.0237 - acc: 0.9760 - mean_squared_error: 0.0207
  6500/173046 [>.............................] - ETA: 1s - loss: 0.0766 - acc: 0.9751 - mean_squared_error: 0.0214
 12750/173046 [=>............................] - ETA: 1s - loss: 0.0751 - acc: 0.9729 - mean_squared_error: 0.0227
 19000/173046 [==>...........................] - ETA: 1s - loss: 0.0829 - acc: 0.9717 - mean_squared_error: 0.0240
 25250/173046 [===>..........................] - ETA: 1s - loss: 0.0832 - acc: 0.9707 - mean_squared_error: 0.0247
 31500/173046 [====>.........................] - ETA: 1s - loss: 0.0834 - acc: 0.9700 - mean_squared_error: 0.0251
 37750/173046 [=====>........................] - ETA: 1s - loss: 0.0815 - acc: 0.9694 - mean_squared_error: 0.0258
 44000/173046 [======>.......................] - ETA: 1s - loss: 0.0807 - acc: 0.9702 - mean_squared_error: 0.0251
 50250/173046 [=======>......................] - ETA: 1s - loss: 0.0779 - acc: 0.9702 - mean_squared_error: 0.0250
 56500/173046 [========>.....................] - ETA: 0s - loss: 0.0766 - acc: 0.9705 - mean_squared_error: 0.0249
 62750/173046 [=========>....................] - ETA: 0s - loss: 0.0778 - acc: 0.9700 - mean_squared_error: 0.0254
 69000/173046 [==========>...................] - ETA: 0s - loss: 0.0776 - acc: 0.9700 - mean_squared_error: 0.0254
 75250/173046 [============>.................] - ETA: 0s - loss: 0.0777 - acc: 0.9702 - mean_squared_error: 0.0252
 81500/173046 [=============>................] - ETA: 0s - loss: 0.0783 - acc: 0.9705 - mean_squared_error: 0.0251
 87750/173046 [==============>...............] - ETA: 0s - loss: 0.0785 - acc: 0.9706 - mean_squared_error: 0.0249
 94000/173046 [===============>..............] - ETA: 0s - loss: 0.0777 - acc: 0.9705 - mean_squared_error: 0.0249
100250/173046 [================>.............] - ETA: 0s - loss: 0.0780 - acc: 0.9705 - mean_squared_error: 0.0250
106500/173046 [=================>............] - ETA: 0s - loss: 0.0769 - acc: 0.9704 - mean_squared_error: 0.0250
112750/173046 [==================>...........] - ETA: 0s - loss: 0.0777 - acc: 0.9704 - mean_squared_error: 0.0251
119000/173046 [===================>..........] - ETA: 0s - loss: 0.0781 - acc: 0.9704 - mean_squared_error: 0.0250
125250/173046 [====================>.........] - ETA: 0s - loss: 0.0779 - acc: 0.9705 - mean_squared_error: 0.0249
131500/173046 [=====================>........] - ETA: 0s - loss: 0.0772 - acc: 0.9705 - mean_squared_error: 0.0249
137750/173046 [======================>.......] - ETA: 0s - loss: 0.0782 - acc: 0.9705 - mean_squared_error: 0.0250
144000/173046 [=======================>......] - ETA: 0s - loss: 0.0786 - acc: 0.9705 - mean_squared_error: 0.0250
150250/173046 [=========================>....] - ETA: 0s - loss: 0.0781 - acc: 0.9705 - mean_squared_error: 0.0250
156500/173046 [==========================>...] - ETA: 0s - loss: 0.0786 - acc: 0.9705 - mean_squared_error: 0.0250
162750/173046 [===========================>..] - ETA: 0s - loss: 0.0783 - acc: 0.9705 - mean_squared_error: 0.0250
169000/173046 [============================>.] - ETA: 0s - loss: 0.0783 - acc: 0.9705 - mean_squared_error: 0.0251
173046/173046 [==============================] - 2s 10us/step - loss: 0.0785 - acc: 0.9705 - mean_squared_error: 0.0250 - val_loss: 4.8025e-04 - val_acc: 0.9723 - val_mean_squared_error: 0.0241

Epoch 00050: val_loss did not improve
                         : Elapsed time for training with 173046 events: 89.9 sec         
                         : Creating xml weight file: [0;36mdataset/weights/TMVAClassification_PyKeras.weights.xml[0m
                         : Creating standalone class: [0;36mdataset/weights/TMVAClassification_PyKeras.class.C[0m
Factory                  : Training finished
                         : 
                         : Ranking input variables (method specific)...
BDT                      : Ranking result (top variable is best ranked)
                         : ----------------------------------------------------
                         : Rank : Variable           : Variable Importance
                         : ----------------------------------------------------
                         :    1 : mt2ll              : 2.257e-01
                         :    2 : METcorrected_pt    : 8.890e-02
                         :    3 : r2l4j              : 8.790e-02
                         :    4 : r2l                : 8.312e-02
                         :    5 : mt2bl              : 7.383e-02
                         :    6 : dphillmet          : 7.209e-02
                         :    7 : mblt               : 6.925e-02
                         :    8 : massT              : 6.887e-02
                         :    9 : cosphill           : 4.227e-02
                         :   10 : dark_pt            : 4.223e-02
                         :   11 : overlapping_factor : 4.221e-02
                         :   12 : reco_weight        : 4.195e-02
                         :   13 : costhetall         : 3.904e-02
                         :   14 : nbJet              : 2.269e-02
                         : ----------------------------------------------------
                         : No variable ranking supplied by classifier: PyKeras
Factory                  : === Destroy and recreate all methods via weight files for testing ===
                         : 
Factory                  : [1mTest all methods[0m
Factory                  : Test method: BDT for Classification performance
                         : 
BDT                      : [dataset] : Evaluation of BDT on testing sample (74162 events)
                         : Elapsed time for evaluation of 74162 events: 1.79 sec       
Factory                  : Test method: PyKeras for Classification performance
                         : 
                         : Load model from file: /gpfs/users/bolivars/CMSSW_10_4_0/src/TopPlusDMRunIILegacy/neuralNetwork//2016/DMscalar_Dilepton_top_tWChan_Mchi1_Mphi50_TTbar/training/PyKerasTrained1.h5
Factory                  : [1mEvaluate all methods[0m
Factory                  : Evaluate classifier: BDT
                         : 
BDT                      : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_BDT            :           Variable                  Mean                  RMS          [        Min                  Max ]
                         : -------------------------------------------------------------------------------------------------------------
                         :              nbJet:              1.6632             0.51499   [              1.0000              5.0000 ]
                         :               mblt:              127.26              61.857   [              12.133              1115.0 ]
                         :    METcorrected_pt:              164.49              112.27   [              1.6532              1134.7 ]
                         :              mt2ll:              114.78              61.027   [              80.000              954.46 ]
                         :          dphillmet:           -0.026340              2.1619   [             -3.1415              3.1416 ]
                         :              mt2bl:              258.20              140.56   [              91.532              2957.5 ]
                         :              massT:              488.54              231.33   [              178.08              2638.5 ]
                         :           cosphill:             -47.588              49.221   [             -99.000             0.99980 ]
                         :         costhetall:             -47.355              49.443   [             -99.000             0.96336 ]
                         :                r2l:              1.0807             0.63318   [           0.0064758              11.720 ]
                         :              r2l4j:             0.41154             0.19971   [           0.0024672              1.9060 ]
                         :        reco_weight:             -46.612              50.162   [             -99.000              6.2711 ]
                         :            dark_pt:              125.11              325.88   [             -99.000              6580.3 ]
                         : overlapping_factor:             -46.722              50.052   [             -99.000              43.137 ]
                         : -------------------------------------------------------------------------------------------------------------
Factory                  : Evaluate classifier: PyKeras
                         : 
TFHandler_PyKeras        :           Variable                  Mean                  RMS          [        Min                  Max ]
                         : -------------------------------------------------------------------------------------------------------------
                         :              nbJet:            -0.66839             0.25750   [             -1.0000              1.0000 ]
                         :               mblt:            -0.78643             0.11660   [             -1.0034              1.0754 ]
                         :    METcorrected_pt:            -0.89062            0.075745   [             -1.0005            -0.23606 ]
                         :              mt2ll:            -0.89335             0.18715   [             -1.0000              1.6817 ]
                         :          dphillmet:          -0.0083842             0.68816   [            -0.99997              1.0000 ]
                         :              mt2bl:            -0.87250            0.099010   [            -0.98990              1.0289 ]
                         :              massT:            -0.70059             0.19727   [            -0.96534              1.1329 ]
                         :           cosphill:            0.028248             0.98441   [             -1.0000              1.0000 ]
                         :         costhetall:            0.033277             0.98922   [             -1.0000             0.99999 ]
                         :                r2l:            -0.85421            0.086225   [             -1.0005             0.59469 ]
                         :              r2l4j:            -0.89714            0.050388   [             -1.0004            -0.52007 ]
                         :        reco_weight:          -0.0048189             0.95289   [             -1.0000             0.99977 ]
                         :            dark_pt:            -0.95115            0.071025   [             -1.0000             0.45577 ]
                         : overlapping_factor:            -0.43343             0.54244   [             -1.0000             0.54043 ]
                         : -------------------------------------------------------------------------------------------------------------
PyKeras                  : [dataset] : Loop over test events and fill histograms with classifier response...
                         : 
TFHandler_PyKeras        :           Variable                  Mean                  RMS          [        Min                  Max ]
                         : -------------------------------------------------------------------------------------------------------------
                         :              nbJet:            -0.66839             0.25750   [             -1.0000              1.0000 ]
                         :               mblt:            -0.78643             0.11660   [             -1.0034              1.0754 ]
                         :    METcorrected_pt:            -0.89062            0.075745   [             -1.0005            -0.23606 ]
                         :              mt2ll:            -0.89335             0.18715   [             -1.0000              1.6817 ]
                         :          dphillmet:          -0.0083842             0.68816   [            -0.99997              1.0000 ]
                         :              mt2bl:            -0.87250            0.099010   [            -0.98990              1.0289 ]
                         :              massT:            -0.70059             0.19727   [            -0.96534              1.1329 ]
                         :           cosphill:            0.028248             0.98441   [             -1.0000              1.0000 ]
                         :         costhetall:            0.033277             0.98922   [             -1.0000             0.99999 ]
                         :                r2l:            -0.85421            0.086225   [             -1.0005             0.59469 ]
                         :              r2l4j:            -0.89714            0.050388   [             -1.0004            -0.52007 ]
                         :        reco_weight:          -0.0048189             0.95289   [             -1.0000             0.99977 ]
                         :            dark_pt:            -0.95115            0.071025   [             -1.0000             0.45577 ]
                         : overlapping_factor:            -0.43343             0.54244   [             -1.0000             0.54043 ]
                         : -------------------------------------------------------------------------------------------------------------
                         : 
                         : Evaluation results ranked by best signal efficiency and purity (area)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet       MVA                       
                         : Name:         Method:          ROC-integ
                         : dataset       BDT            : 0.971
                         : dataset       PyKeras        : 0.966
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
                         : Testing efficiency compared to training efficiency (overtraining check)
                         : -------------------------------------------------------------------------------------------------------------------
                         : DataSet              MVA              Signal efficiency: from test sample (from training sample) 
                         : Name:                Method:          @B=0.01             @B=0.10            @B=0.30   
                         : -------------------------------------------------------------------------------------------------------------------
                         : dataset              BDT            : 0.824 (0.822)       0.931 (0.930)      0.970 (0.969)
                         : dataset              PyKeras        : 0.787 (0.784)       0.905 (0.904)      0.963 (0.963)
                         : -------------------------------------------------------------------------------------------------------------------
                         : 
Dataset:dataset          : Created tree 'TestTree' with 74162 events
                         : 
Dataset:dataset          : Created tree 'TrainTree' with 173046 events
                         : 
Factory                  : [1mThank you for using TMVA![0m
                         : [1mFor citation information, please visit: http://tmva.sf.net/citeTMVA.html[0m
